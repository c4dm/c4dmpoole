
<!-- This document was automatically generated with bibtex2html 1.96
     (see http://www.lri.fr/~filliatr/bibtex2html/),
     with the following command:
     ./bibtex2html -nodoc -dl -a -noabstract -nokeywords -o pubs2021_raw pubs2021.bib  -->


<dl>

<dt>
[<a name="agrawal2021structureawarenetworks">1</a>]
</dt>
<dd>
R&nbsp;Agrawal, D&nbsp;Wolff, and S&nbsp;Dixon.
 Structure-aware audio-to-score alignment using progressively dilated
  convolutional neural networks.
 In <em>ICASSP 2021 - 2021 IEEE International Conference on
  Acoustics, Speech and Signal Processing (ICASSP)</em>. IEEE, Jun 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#agrawal2021structureawarenetworks">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/icassp39728.2021.9414049">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="bear2021angeotagging">2</a>]
</dt>
<dd>
H&nbsp;Bear, V&nbsp;Morfi, and E&nbsp;Benetos.
 An evaluation of data augmentation methods for sound scene
  geotagging.
 In <em>22nd Annual Conference of the International Speech
  Communication Association (INTERSPEECH)</em>, pages 581-585. Brno, Czech
  Republic, International Speech and Communication Association (ISCA), Aug
  2021.
[&nbsp;<a href="pubs2021_raw_bib.html#bear2021angeotagging">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Interspeech.2021-1837">DOI</a>&nbsp;| 
<a href="https://www.interspeech2021.org/">http</a>&nbsp;]

</dd>


<dt>
[<a name="benitotemprano2021aguitar">3</a>]
</dt>
<dd>
A&nbsp;Benito&nbsp;Temprano and AP&nbsp;Mcpherson.
 A tmr angle sensor for gesture acquisition and disambiguation on the
  electric guitar.
 In <em>Audio Mostly 2021 (AM'21). Sonic experiences in the era of
  the Internet of Sounds</em>. University of Trento (Italy) [Online], Sep 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#benitotemprano2021aguitar">bib</a>&nbsp;]

</dd>


<dt>
[<a name="bodo2021aidentification">4</a>]
</dt>
<dd>
RPP Bodo, E&nbsp;Benetos, and M&nbsp;Queiroz.
 A framework for music similarity and cover song identification.
 In <em>15th International Symposium on Computer Music
  Multidisciplinary Research (CMMR)</em>. Tokyo, Japan, Nov 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#bodo2021aidentification">bib</a>&nbsp;| 
<a href="https://www.cmmr2021.gttm.jp/">http</a>&nbsp;]

</dd>


<dt>
[<a name="cheuk2021revisitingattention">5</a>]
</dt>
<dd>
KW&nbsp;Cheuk, Y-J Luo, E&nbsp;Benetos, and D&nbsp;Herremans.
 Revisiting the onsets and frames model with additive attention.
 In <em>International Joint Conference on Neural Networks (IJCNN)</em>.
  IEEE, Jul 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#cheuk2021revisitingattention">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/IJCNN52387.2021.9533407">DOI</a>&nbsp;| 
<a href="https://www.ijcnn.org/">http</a>&nbsp;]

</dd>


<dt>
[<a name="clemente2021musicalsensitivity">6</a>]
</dt>
<dd>
A&nbsp;Clemente, MT&nbsp;Pearce, and M&nbsp;Nadal.
 Musical aesthetic sensitivity.
 <em>Psychology of Aesthetics Creativity and the Arts</em>, Mar 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#clemente2021musicalsensitivity">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1037/aca0000381">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="clemente2021evaluativedesigns">7</a>]
</dt>
<dd>
A&nbsp;Clemente, MT&nbsp;Pearce, M&nbsp;Skov, and M&nbsp;Nadal.
 Evaluative judgment across domains: Liking balance, contour, symmetry
  and complexity in melodies and visual designs.
 <em>Brain and Cognition</em>, 151, Jul 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#clemente2021evaluativedesigns">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.bandc.2021.105729">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="colonel2021reverseprocessing">8</a>]
</dt>
<dd>
JT&nbsp;Colonel and J&nbsp;Reiss.
 Reverse engineering of a recording mix with differentiable digital
  signal processing.
 <em>Journal of the Acoustical Society of America</em>, 150(1):608-619,
  Jul 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#colonel2021reverseprocessing">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1121/10.0005622">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="daniele2021whatcreativity">9</a>]
</dt>
<dd>
A&nbsp;Daniele, C&nbsp;Di&nbsp;Bernardi&nbsp;Luft, and N&nbsp;Bryan-Kinns.
 “what is human?” a turing test for artistic creativity.
 volume 12693 LNCS, pages 396-411. Jan 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#daniele2021whatcreativity">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/978-3-030-72914-1_26">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="defleurian2021theanalysis">10</a>]
</dt>
<dd>
R&nbsp;de&nbsp;Fleurian and MT&nbsp;Pearce.
 The relationship between valence and chills in music: A corpus
  analysis.
 <em>i-Perception</em>, 12(4):1-11, Jul 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#defleurian2021theanalysis">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1177/20416695211024680">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="delbosquetrevinoinvestigatingcomponents">11</a>]
</dt>
<dd>
J&nbsp;Del-Bosque-Trevino, M&nbsp;Purver, and J&nbsp;HOUGH.
 Investigating the semantic wave in tutorial dialogues: An annotation
  scheme and corpus study on analogy components.
 In <em>24th Workshop on the Semantics and Pragmatics of Dialogue
  (SemDial)</em>. Brandeis University, Waltham, MA, USA.
[&nbsp;<a href="pubs2021_raw_bib.html#delbosquetrevinoinvestigatingcomponents">bib</a>&nbsp;]

</dd>


<dt>
[<a name="demirel2021lowrecordings">12</a>]
</dt>
<dd>
E&nbsp;Demirel, S&nbsp;Ahlbäck, and S&nbsp;Dixon.
 Low resource audio-to-lyrics alignment from polyphonic music
  recordings.
 volume&nbsp;00, pages 586-590, Jun 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#demirel2021lowrecordings">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/icassp39728.2021.9414395">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="fang2021usingdisease">13</a>]
</dt>
<dd>
Y&nbsp;Fang, J&nbsp;Ou, N&nbsp;Bryan-Kinns, Q&nbsp;Kang, J&nbsp;Zhang, and B&nbsp;Guo.
 Using vibrotactile device in music therapy to support wellbeing for
  people with alzheimer’s disease.
 volume 261, pages 353-361. Jan 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#fang2021usingdisease">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/978-3-030-79760-7_43">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="ford2021creativitycomposition">14</a>]
</dt>
<dd>
C&nbsp;Ford, N&nbsp;Bryan-Kinns, and C&nbsp;Nash.
 Creativity in children's digital music composition.
 In R&nbsp;Dannenberg and X&nbsp;Xiao, editors, <em>New Instruments for Music
  Expression</em>. NYU Shanghai, Shanghai.,
  https://nime.pubpub.org/pub/ker5w948/release/1, Jun 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#ford2021creativitycomposition">bib</a>&nbsp;]

</dd>


<dt>
[<a name="gabrielli2021speciallistening">15</a>]
</dt>
<dd>
L&nbsp;Gabrielli, G&nbsp;Fazekas, and J&nbsp;Nam.
 Special issue on deep learning for applications in acoustics:
  Modeling, synthesis, and listening.
 <em>Applied Sciences (Switzerland)</em>, 11(2):1-4, Jan 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#gabrielli2021speciallistening">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.3390/app11020473">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="gan2021towardssubstitution">16</a>]
</dt>
<dd>
Y&nbsp;Gan, X&nbsp;Chen, Q&nbsp;Huang, M&nbsp;Purver, JR&nbsp;Woodward, J&nbsp;Xie, and P&nbsp;Huang.
 Towards robustness of text-to-sql models against synonym
  substitution.
 pages 2505-2515. Association for Computational Linguistics, 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#gan2021towardssubstitution">bib</a>&nbsp;| 
<a href="https://aclanthology.org/volumes/2021.acl-long/">http</a>&nbsp;]

</dd>


<dt>
[<a name="graf2021anvisualisation">17</a>]
</dt>
<dd>
M&nbsp;Graf, HC&nbsp;Opara, and M&nbsp;Barthet.
 An audio-driven system for real-time music visualisation.
 In <em>Audio Engineering Society Convention 150</em>, Jun 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#graf2021anvisualisation">bib</a>&nbsp;| 
<a href="https://maxgraf.space/">http</a>&nbsp;]

</dd>


<dt>
[<a name="hall2021astructure">18</a>]
</dt>
<dd>
ETR Hall and MT&nbsp;Pearce.
 A model of large-scale thematic structure.
 <em>Journal of New Music Research</em>, 50(3):220-241, May 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#hall2021astructure">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1080/09298215.2021.1930062">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="hansenpredictiveperception">19</a>]
</dt>
<dd>
NC&nbsp;Hansen, H&nbsp;Kragness, P&nbsp;Vuust, L&nbsp;Trainor, and M&nbsp;Pearce.
 Predictive uncertainty underlies auditory-boundary perception.
 <em>Psychological Science</em>.
[&nbsp;<a href="pubs2021_raw_bib.html#hansenpredictiveperception">bib</a>&nbsp;]

</dd>


<dt>
[<a name="harrison2021erratum101371journalpcbi1008304">20</a>]
</dt>
<dd>
PMC Harrison, R&nbsp;Bianco, M&nbsp;Chait, and MT&nbsp;Pearce.
 Erratum: Ppm-decay: A computational model of auditory prediction with
  memory decay (plos comput biol (2021) 16: 11 (e1008304) doi:
  10.1371/journal.pcbi.1008304).
 <em>PLoS Computational Biology</em>, 17(5), May 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#harrison2021erratum101371journalpcbi1008304">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1371/journal.pcbi.1008995">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="hayesneuralsynthesis">21</a>]
</dt>
<dd>
B&nbsp;Hayes, C&nbsp;Saitis, and G&nbsp;Fazekas.
 Neural waveshaping synthesis.
 In <em>Proceedings of the 22nd International Society for Music
  Information Retrieval</em>. Online.
[&nbsp;<a href="pubs2021_raw_bib.html#hayesneuralsynthesis">bib</a>&nbsp;| 
<a href="https://benhayes.net/">http</a>&nbsp;]

</dd>


<dt>
[<a name="healey2021humanlikecommunication">22</a>]
</dt>
<dd>
PGT Healey.
 Human-like communication.
 pages 137-151. Jul 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#healey2021humanlikecommunication">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1093/oso/9780198862536.003.0007">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="holzapfelhumanitiestranscription">23</a>]
</dt>
<dd>
A&nbsp;Holzapfel, E&nbsp;Benetos, A&nbsp;Killick, and R&nbsp;Widdess.
 Humanities and engineering perspectives on music transcription.
 <em>Digital Scholarship in the Humanities</em>.
[&nbsp;<a href="pubs2021_raw_bib.html#holzapfelhumanitiestranscription">bib</a>&nbsp;| 
<a href="https://academic.oup.com/dsh">http</a>&nbsp;]

</dd>


<dt>
[<a name="jing2021theuse">24</a>]
</dt>
<dd>
C&nbsp;Jing, N&nbsp;Bryan-Kinns, S&nbsp;Yang, J&nbsp;Zhi, and J&nbsp;Zhang.
 The influence of mobile phone location and screen orientation on
  driving safety and the usability of car-sharing software in-car use.
 <em>International Journal of Industrial Ergonomics</em>, 84, Jul 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#jing2021theuse">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.ergon.2021.103168">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="karan2021mitigatingdialogue">25</a>]
</dt>
<dd>
M&nbsp;Karan, P&nbsp;Khare, P&nbsp;Healey, and M&nbsp;Purver.
 Mitigating topic bias when detecting decisions in dialogue.
 In <em>SIGDIAL: 22nd Annual Meeting of the Special Interest Group on
  Discourse and Dialogue</em>, Jul 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#karan2021mitigatingdialogue">bib</a>&nbsp;| 
<a href="https://sigdial.org/sites/default/files/workshops/conference22/Proceedings/pdf/2021.sigdial-1.56.pdf">.pdf</a>&nbsp;]

</dd>


<dt>
[<a name="kirby2021thetransform">26</a>]
</dt>
<dd>
T&nbsp;Kirby and M&nbsp;Sandler.
 The evolution of drum modes with strike intensity: Analysis and
  synthesis using the discrete cosine transform.
 <em>J Acoust Soc Am</em>, 150(1):202, Jul 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#kirby2021thetransform">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1121/10.0005509">DOI</a>&nbsp;| 
<a href="https://www.ncbi.nlm.nih.gov/pubmed/34340487">http</a>&nbsp;]

</dd>


<dt>
[<a name="krishnaneffectssequences">27</a>]
</dt>
<dd>
S&nbsp;Krishnan, D&nbsp;Carey, F&nbsp;Dick, and MT&nbsp;Pearce.
 Effects of statistical learning in passive and active contexts on
  reproduction and recognition of auditory sequences.
 <em>Journal of Experimental Psychology: General</em>.
[&nbsp;<a href="pubs2021_raw_bib.html#krishnaneffectssequences">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1037/xge0001091">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="lefford2021contextawaresystems">28</a>]
</dt>
<dd>
MN&nbsp;Lefford, G&nbsp;Bromham, G&nbsp;Fazekas, and D&nbsp;Moffat.
 Context-aware intelligent mixing systems.
 <em>AES: Journal of the Audio Engineering Society</em>, 69(3):128-141,
  Mar 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#lefford2021contextawaresystems">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.17743/JAES.2020.0043">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="li2021achallenge">29</a>]
</dt>
<dd>
S&nbsp;Li, Y&nbsp;Jing, and G&nbsp;Fazekas.
 A novel dataset for the identification of computer generated melodies
  in the csmt challenge.
 volume 761 LNEE, pages 177-186. Jan 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#li2021achallenge">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/978-981-16-1649-5_15">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="liang2021knitsensing">30</a>]
</dt>
<dd>
A&nbsp;Liang, R&nbsp;Stewart, R&nbsp;Freire, and N&nbsp;Bryan-Kinns.
 Knit stretch sensor placement for body movement sensing.
 Feb 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#liang2021knitsensing">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3430524.3440629">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="liu2021fromnotation">31</a>]
</dt>
<dd>
L&nbsp;Liu and E&nbsp;Benetos.
 From audio to music notation.
 Number&nbsp;24 in Artificial Intelligence, pages 693-714. Springer
  International Publishing, Cham, Switzerland, 1st edition, Aug 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#liu2021fromnotation">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/978-3-030-72116-9_24">DOI</a>&nbsp;| 
<a href="https://cheriell.github.io/">http</a>&nbsp;]

</dd>


<dt>
[<a name="liu2021jointmusic">32</a>]
</dt>
<dd>
L&nbsp;Liu, G-V Morfi, and E&nbsp;Benetos.
 Joint multi-pitch detection and score transcription for polyphonic
  piano music.
 In <em>IEEE International Conference on Acoustics, Speech and Signal
  Processing</em>. Toronto, Canada, IEEE, Jun 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#liu2021jointmusic">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP39728.2021.9413601">DOI</a>&nbsp;| 
<a href="https://cheriell.github.io/">http</a>&nbsp;]

</dd>


<dt>
[<a name="lbberssketchingassociations">33</a>]
</dt>
<dd>
S&nbsp;Löbbers, M&nbsp;Barthet, and G&nbsp;Fazekas.
 Sketching sounds: an exploratory study on sound-shape associations.
 In <em>International Computer Music Conference</em>. Santiago de Chile,
  Chile.
[&nbsp;<a href="pubs2021_raw_bib.html#lbberssketchingassociations">bib</a>&nbsp;]

</dd>


<dt>
[<a name="manco2021muscapsaudio">34</a>]
</dt>
<dd>
I&nbsp;Manco, E&nbsp;Benetos, E&nbsp;Quinton, and G&nbsp;Fazekas.
 Muscaps: generating captions for music audio.
 In <em>International Joint Conference on Neural Networks (IJCNN)</em>.
  IEEE, Jul 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#manco2021muscapsaudio">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/IJCNN52387.2021.9533461">DOI</a>&nbsp;| 
<a href="https://ilariamanco.com/">http</a>&nbsp;]

</dd>


<dt>
[<a name="miller2021discoveringcollections">35</a>]
</dt>
<dd>
J&nbsp;Miller, V&nbsp;Nicosia, and M&nbsp;Sandler.
 Discovering common practice: Using graph theory to compare harmonic
  sequences in musical audio collections.
 pages 93-97, Jul 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#miller2021discoveringcollections">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3469013.3469025">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="morfi2021deepevents">36</a>]
</dt>
<dd>
V&nbsp;Morfi, RF&nbsp;Lachlan, and D&nbsp;Stowell.
 Deep perceptual embeddings for unlabelled animal sound events.
 <em>Journal of the Acoustical Society of America</em>, 150(1):2-11, Jul
  2021.
[&nbsp;<a href="pubs2021_raw_bib.html#morfi2021deepevents">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1121/10.0005475">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="moro2021performerinstrument">37</a>]
</dt>
<dd>
G&nbsp;Moro and AP&nbsp;McPherson.
 Performer experience on a continuous keyboard instrument.
 <em>Computer Music Journal</em>, 44(2-3):69-91, Jul 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#moro2021performerinstrument">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1162/COMJ_a_00565">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="nagele2021interactiveperformance">38</a>]
</dt>
<dd>
AN&nbsp;Nagele, V&nbsp;Bauer, PGT Healey, JD&nbsp;Reiss, H&nbsp;Cooke, T&nbsp;Cowlishaw, C&nbsp;Baume, and
  C&nbsp;Pike.
 Interactive audio augmented reality in participatory performance.
 <em>Frontiers in Virtual Reality</em>, 1:610320, Feb 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#nagele2021interactiveperformance">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.3389/frvir.2020.610320">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="nasreen2021rareclassdiagnosis">39</a>]
</dt>
<dd>
S&nbsp;Nasreen, J&nbsp;HOUGH, and M&nbsp;Purver.
 Rare-class dialogue act tagging for alzheimer's disease diagnosis.
 In <em>SIGDIAL: 22nd Annual Meeting of the Special Interest Group on
  Discourse and Dialogue</em>, Jul 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#nasreen2021rareclassdiagnosis">bib</a>&nbsp;| 
<a href="https://sigdial.org/sites/default/files/workshops/conference22/Proceedings/pdf/2021.sigdial-1.32.pdf">.pdf</a>&nbsp;]

</dd>


<dt>
[<a name="nasreen2021alzheimersfeatures">40</a>]
</dt>
<dd>
S&nbsp;Nasreen, M&nbsp;Rohanian, J&nbsp;Hough, and M&nbsp;Purver.
 Alzheimer’s dementia recognition from spontaneous speech using
  disfluency and interactional features.
 <em>Frontiers in Computer Science</em>, 3:640669-640669, Jun 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#nasreen2021alzheimersfeatures">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.3389/fcomp.2021.640669">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="nonnis2021ollytogetherness">41</a>]
</dt>
<dd>
A&nbsp;Nonnis and N&nbsp;Bryan-Kinns.
 Olly: A tangible for togetherness.
 <em>International Journal of Human Computer Studies</em>, 153, Apr 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#nonnis2021ollytogetherness">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.ijhcs.2021.102647">DOI</a>&nbsp;| 
<a href="https://doi.org/10.1016/j.ijhcs.2021.102647">http</a>&nbsp;]

</dd>


<dt>
[<a name="ohanlon2021detectingnetworks">42</a>]
</dt>
<dd>
K&nbsp;O'Hanlon, E&nbsp;Benetos, and S&nbsp;Dixon.
 Detecting cover songs with pitch class key-invariant networks.
 In <em>IEEE International Workshop on Machine Learning for Signal
  Processing (MLSP)</em>. Gold Coast, Queensland, Australia, IEEE, Oct 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#ohanlon2021detectingnetworks">bib</a>&nbsp;| 
<a href="https://2021.ieeemlsp.org/">http</a>&nbsp;]

</dd>


<dt>
[<a name="ohanlon2021fifthnetrecognition">43</a>]
</dt>
<dd>
K&nbsp;O'Hanlon and M&nbsp;Sandler.
 Fifthnet: Structured compact neural networks for automatic chord
  recognition.
 <em>IEEE/ACM Transactions on Audio Speech and Language Processing</em>,
  29:2671-2682, Jan 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#ohanlon2021fifthnetrecognition">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TASLP.2021.3070158">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="ozaki2021agreementsongs">44</a>]
</dt>
<dd>
Y&nbsp;Ozaki, J&nbsp;McBride, E&nbsp;Benetos, PQ&nbsp;Pfordresher, J&nbsp;Six, A&nbsp;T.&nbsp;Tierney,
  P&nbsp;Proutskova, E&nbsp;Sakai, H&nbsp;Kondo, H&nbsp;Fukatsu, S&nbsp;Fujii, and PE&nbsp;Savage.
 Agreement among human and annotated transcriptions of global songs.
 In <em>22nd International Society for Music Information Retrieval
  Conference (ISMIR)</em>. International Society for Music Information Retrieval,
  Nov 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#ozaki2021agreementsongs">bib</a>&nbsp;| 
<a href="https://ismir2021.ismir.net/">http</a>&nbsp;]

</dd>


<dt>
[<a name="ozkan2021specificconversations">45</a>]
</dt>
<dd>
EE&nbsp;Ozkan, T&nbsp;Gurion, J&nbsp;Hough, PGT Healey, and L&nbsp;Jamone.
 Specific hand motion patterns correlate to miscommunications during
  dyadic conversations.
 Aug 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#ozkan2021specificconversations">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICDL49984.2021.9515613">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="park2021shouldblush">46</a>]
</dt>
<dd>
S&nbsp;Park, PGT Healey, and A&nbsp;Kaniadakis.
 Should robots blush?
 May 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#park2021shouldblush">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3411764.3445561">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="pelicon2021zeroshotdetection">47</a>]
</dt>
<dd>
A&nbsp;Pelicon, R&nbsp;Shekhar, M&nbsp;Martinc, B&nbsp;Škrlj, M&nbsp;Purver, and S&nbsp;Pollak.
 Zero-shot cross-lingual content filtering: Offensive language and
  hate speech detection.
 In <em>EACL workshop on News Media Content Analysis and Automated
  Report Generation</em>, pages 30-34. Kyiv (online), Apr 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#pelicon2021zeroshotdetection">bib</a>&nbsp;]

</dd>


<dt>
[<a name="pelicon2021investigatingdetection">48</a>]
</dt>
<dd>
A&nbsp;Pelicon, R&nbsp;Shekhar, B&nbsp;Skrlj, M&nbsp;Purver, and S&nbsp;Pollak.
 Investigating cross-lingual training for offensive language
  detection.
 <em>PeerJ Comput. Sci.</em>, 7:e559-e559, Jun 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#pelicon2021investigatingdetection">bib</a>&nbsp;]

</dd>


<dt>
[<a name="pham2021cnnmoedetection">49</a>]
</dt>
<dd>
LD&nbsp;Pham, H&nbsp;Phan, R&nbsp;Palaniappan, A&nbsp;Mertins, and I&nbsp;Mcloughlin.
 Cnn-moe based framework for classification of respiratory anomalies
  and lung disease detection.
 <em>IEEE Journal of Biomedical and Health Informatics</em>, PP, Mar
  2021.
[&nbsp;<a href="pubs2021_raw_bib.html#pham2021cnnmoedetection">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/JBHI.2021.3064237">DOI</a>&nbsp;| 
<a href="https://www.ncbi.nlm.nih.gov/pubmed/33684048">http</a>&nbsp;]

</dd>


<dt>
[<a name="phan2021xsleepnetstaging">50</a>]
</dt>
<dd>
H&nbsp;Phan, OY&nbsp;Chen, MC&nbsp;Tran, P&nbsp;Koch, A&nbsp;Mertins, and M&nbsp;De&nbsp;Vos.
 Xsleepnet: Multi-view sequential model for automatic sleep staging.
 <em>IEEE Trans Pattern Anal Mach Intell</em>, PP, Mar 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#phan2021xsleepnetstaging">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TPAMI.2021.3070057">DOI</a>&nbsp;| 
<a href="https://www.ncbi.nlm.nih.gov/pubmed/33788679">http</a>&nbsp;]

</dd>


<dt>
[<a name="pollak2021embeddiacontributions">51</a>]
</dt>
<dd>
S&nbsp;Pollak, M&nbsp;Robnik-Šikonja, M&nbsp;Purver, M&nbsp;Boggia, R&nbsp;Shekhar, M&nbsp;Pranjić,
  S&nbsp;Salmela, I&nbsp;Krustok, T&nbsp;Paju, C-G Linden, L&nbsp;Leppànen, E&nbsp;Zosa, M&nbsp;Ulčar,
  L&nbsp;Freiental, S&nbsp;Traat, LA&nbsp;Cabrera-Diego, M&nbsp;Martinc, N&nbsp;Lavrač, B&nbsp;Škrlj,
  M&nbsp;Žnidaršič, A&nbsp;Pelicon, B&nbsp;Koloski, V&nbsp;Podpečan, J&nbsp;Kranjc, S&nbsp;Sheehan,
  E&nbsp;Boros, J&nbsp;Moreno, A&nbsp;Doucet, and H&nbsp;Toivonen.
 Embeddia tools, datasets and challenges: Resources and hackathon
  contributions.
 In <em>EACL workshop on News Media Content Analysis and Automated
  Report Generation</em>, pages 99-109. Kyiv (online), Apr 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#pollak2021embeddiacontributions">bib</a>&nbsp;]

</dd>


<dt>
[<a name="purver2021incrementalsemantics">52</a>]
</dt>
<dd>
M&nbsp;Purver, M&nbsp;Sadrzadeh, R&nbsp;Kempson, G&nbsp;Wijnholds, and J&nbsp;Hough.
 Incremental composition in distributional semantics.
 <em>Journal of Logic, Language and Information</em>, Jul 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#purver2021incrementalsemantics">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/s10849-021-09337-8">DOI</a>&nbsp;| 
<a href="https://doi.org/10.1007/s10849-021-09337-8">http</a>&nbsp;]

</dd>


<dt>
[<a name="quirogamartinez2021musicianshipdetection">53</a>]
</dt>
<dd>
DR&nbsp;Quiroga-Martinez, NC&nbsp;Hansen, A&nbsp;Højlund, M&nbsp;Pearce, E&nbsp;Brattico, E&nbsp;Holmes,
  K&nbsp;Friston, and P&nbsp;Vuust.
 Musicianship and melodic predictability enhance neural gain in
  auditory cortex during pitch deviance detection.
 <em>Human Brain Mapping</em>, Jan 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#quirogamartinez2021musicianshipdetection">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1002/hbm.25638">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="ragano2021moreannotations">54</a>]
</dt>
<dd>
A&nbsp;Ragano, E&nbsp;Benetos, and A&nbsp;Hines.
 More for less: Non-intrusive speech quality assessment with limited
  annotations.
 In <em>13th International Conference on Quality of Multimedia
  Experience (QoMEX)</em>, Jun 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#ragano2021moreannotations">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/QoMEX51781.2021.9465410">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="ratclife2021extendedopportunities">55</a>]
</dt>
<dd>
J&nbsp;Ratclife, F&nbsp;Soave, N&nbsp;Bryan-Kinns, L&nbsp;Tokarchuk, and I&nbsp;Farkhatdinov.
 Extended reality (xr) remote research: A survey of drawbacks and
  opportunities.
 <em>Conference on Human Factors in Computing Systems - Proceedings</em>,
  May 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#ratclife2021extendedopportunities">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3411764.3445170">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="ratcliffe2021extendedopportunities">56</a>]
</dt>
<dd>
J&nbsp;Ratcliffe, F&nbsp;Soave, N&nbsp;Bryan-Kinns, L&nbsp;Tokarchuk, and I&nbsp;Farkhatdinov.
 Extended reality (xr) remote research: a survey of drawbacks and
  opportunities.
 pages 527:1-527:1. ACM, 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#ratcliffe2021extendedopportunities">bib</a>&nbsp;| 
<a href="https://doi.org/10.1145/3411764">http</a>&nbsp;]

</dd>


<dt>
[<a name="ratcliffe2021remoteexperimentation">57</a>]
</dt>
<dd>
J&nbsp;Ratcliffe, F&nbsp;Soave, M&nbsp;Hoover, FR&nbsp;Ortega, N&nbsp;Bryan-Kinns, L&nbsp;Tokarchuk, and
  I&nbsp;Farkhatdinov.
 Remote xr studies: Exploring three key challenges of remote xr
  experimentation.
 pages 121:1-121:1. ACM, 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#ratcliffe2021remoteexperimentation">bib</a>&nbsp;| 
<a href="https://doi.org/10.1145/3411763">http</a>&nbsp;]

</dd>


<dt>
[<a name="reed2021surfacevocalists">58</a>]
</dt>
<dd>
CN&nbsp;Reed and AP&nbsp;McPherson.
 Surface electromyography for sensing performance intention and
  musical imagery in vocalists.
 Feb 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#reed2021surfacevocalists">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3430524.3440641">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="reiss2021atechniques">59</a>]
</dt>
<dd>
JD&nbsp;Reiss, HE&nbsp;Tez, and R&nbsp;Selfridge.
 A comparative perceptual evaluation of thunder synthesis techniques.
 Jan 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#reiss2021atechniques">bib</a>&nbsp;]

</dd>


<dt>
[<a name="robsononpractitioners">60</a>]
</dt>
<dd>
N&nbsp;Robson, N&nbsp;Bryan-Kinns, and A&nbsp;Mcpherson.
 On mediating space, sound and experience: interviews with situated
  sound art practitioners.
 <em>Organised Sound: an international journal of music and
  technology</em>, 28(1).
[&nbsp;<a href="pubs2021_raw_bib.html#robsononpractitioners">bib</a>&nbsp;]

</dd>


<dt>
[<a name="rohanian2021multimodalspeech">61</a>]
</dt>
<dd>
M&nbsp;Rohanian, J&nbsp;Hough, and M&nbsp;Purver.
 Multi-modal fusion with gating using audio, lexical and disfluency
  features for alzheimer's dementia recognition from spontaneous speech.
 volume abs/2106.09668, 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#rohanian2021multimodalspeech">bib</a>&nbsp;]

</dd>


<dt>
[<a name="sarkar2021vocalnetworks">62</a>]
</dt>
<dd>
S&nbsp;Sarkar, E&nbsp;Benetos, and M&nbsp;Sandler.
 Vocal harmony separation using time-domain neural networks.
 In <em>22nd Annual Conference of the International Speech
  Communication Association (INTERSPEECH)</em>, pages 3515-3519. Brno, Czech
  Republic, Aug 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#sarkar2021vocalnetworks">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Interspeech.2021-1531">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="shukla2021userreality">63</a>]
</dt>
<dd>
R&nbsp;Shukla, R&nbsp;Stewart, and M&nbsp;Sandler.
 User hrtf selection for 3d auditory mixed reality.
 In <em>Sound and Music Computing Conference</em>. Online, Jun 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#shukla2021userreality">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.5281/zenodo.5045168">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="singh2021prototypicalclassification">64</a>]
</dt>
<dd>
S&nbsp;Singh, H&nbsp;Bear, and E&nbsp;Benetos.
 Prototypical networks for domain adaptation in acoustic scene
  classification.
 In <em>IEEE International Conference on Acoustics, Speech and Signal
  Processing</em>. Toronto, Canada, IEEE, Jun 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#singh2021prototypicalclassification">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP39728.2021.9414876">DOI</a>&nbsp;| 
<a href="http://www.eecs.qmul.ac.uk/profiles/singhshubhr.html">.html</a>&nbsp;]

</dd>


<dt>
[<a name="skach2021sensingtrousers">65</a>]
</dt>
<dd>
S&nbsp;Skach, R&nbsp;Stewart, and PGT Healey.
 Sensing social behavior with smart trousers.
 <em>IEEE Pervasive Computing</em>, 20(3):30-40, Jul 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#skach2021sensingtrousers">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/MPRV.2021.3088153">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="soave2021multisensoryapplications">66</a>]
</dt>
<dd>
F&nbsp;Soave, I&nbsp;Farkhatdinov, and N&nbsp;Bryan-Kinns.
 Multisensory teleportation in virtual reality applications.
 pages 377-379, Mar 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#soave2021multisensoryapplications">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/VRW52623.2021.00077">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="soave2021exploringreality">67</a>]
</dt>
<dd>
F&nbsp;Soave, A&nbsp;Padma&nbsp;Kumar, N&nbsp;Bryan-Kinns, and I&nbsp;Farkhatdinov.
 Exploring terminology for perception of motion in virtual reality.
 pages 171-179, Jun 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#soave2021exploringreality">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3461778.3462064">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="steinmetz2021pyloudnormpython">68</a>]
</dt>
<dd>
CJ&nbsp;Steinmetz and JD&nbsp;Reiss.
 Pyloudnorm: A simple yet flexible loudness meter in python.
 Jan 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#steinmetz2021pyloudnormpython">bib</a>&nbsp;]

</dd>


<dt>
[<a name="subramanian2021anomalousmethods">69</a>]
</dt>
<dd>
V&nbsp;Subramanian, S&nbsp;Gururani, E&nbsp;Benetos, and M&nbsp;Sandler.
 Anomalous behaviour in loss-gradient based interpretability methods.
 In <em>RobustML workshop paper at ICLR 2021</em>, May 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#subramanian2021anomalousmethods">bib</a>&nbsp;]

</dd>


<dt>
[<a name="tenderinireducedexposure">70</a>]
</dt>
<dd>
M&nbsp;Tenderini, E&nbsp;De&nbsp;Leeuw, T&nbsp;Eilola, and M&nbsp;Pearce.
 Reduced cross-modal affective priming in the l2 of late bilinguals
  depends on l2 exposure.
 <em>Journal of Experimental Psychology: Learning, Memory, and
  Cognition</em>.
[&nbsp;<a href="pubs2021_raw_bib.html#tenderinireducedexposure">bib</a>&nbsp;]

</dd>


<dt>
[<a name="turchet2021musicalapproach">71</a>]
</dt>
<dd>
L&nbsp;Turchet, D&nbsp;Baker, and T&nbsp;Stockman.
 Musical haptic wearables for synchronisation of visually-impaired
  performers: A co-design approach.
 pages 20-27, Jun 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#turchet2021musicalapproach">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3452918.3458803">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="vahidi2021atagging">72</a>]
</dt>
<dd>
C&nbsp;Vahidi, G&nbsp;Fazekas, and C&nbsp;Saitis.
 A modulation front-end for music audio tagging.
 In <em>The International Joint Conference on Neural Networks</em>, Jul
  2021.
[&nbsp;<a href="pubs2021_raw_bib.html#vahidi2021atagging">bib</a>&nbsp;]

</dd>


<dt>
[<a name="viannalordelo2021pitchinformedshapes">73</a>]
</dt>
<dd>
C&nbsp;Vianna&nbsp;Lordelo, E&nbsp;Benetos, S&nbsp;Dixon, and S&nbsp;Ahlbäck.
 Pitch-informed instrument assignment using a deep convolutional
  network with multiple kernel shapes.
 In <em>22nd International Society for Music Information Retrieval
  Conference (ISMIR)</em>, Nov 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#viannalordelo2021pitchinformedshapes">bib</a>&nbsp;| 
<a href="https://cpvlordelo.github.io/">http</a>&nbsp;]

</dd>


<dt>
[<a name="viannalordelo2021adversarialseparation">74</a>]
</dt>
<dd>
C&nbsp;Vianna&nbsp;Lordelo, E&nbsp;Benetos, S&nbsp;Dixon, S&nbsp;Ahlbäck, and P&nbsp;Ohlsson.
 Adversarial unsupervised domain adaptation for harmonic-percussive
  source separation.
 <em>IEEE Signal Processing Letters</em>, 28:81-85, Jan 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#viannalordelo2021adversarialseparation">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/LSP.2020.3045915">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="yang2021examiningperformance">75</a>]
</dt>
<dd>
S&nbsp;Yang, CN&nbsp;Reed, E&nbsp;Chew, and M&nbsp;Barthet.
 Examining emotion perception agreement in live music performance.
 <em>IEEE Transactions on Affective Computing</em>, Jan 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#yang2021examiningperformance">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TAFFC.2021.3093787">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="zhang2021cosmiccocreation">76</a>]
</dt>
<dd>
Y&nbsp;Zhang, G&nbsp;Xia, M&nbsp;Levy, and S&nbsp;Dixon.
 Cosmic: A conversational interface for human-ai music co-creation.
 In <em>New Interfaces for Musical Expression</em>, Apr 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#zhang2021cosmiccocreation">bib</a>&nbsp;]

</dd>


<dt>
[<a name="zhao2021violinistfeatures">77</a>]
</dt>
<dd>
Y&nbsp;Zhao, C&nbsp;Wang, G&nbsp;Fazekas, E&nbsp;Benetos, and M&nbsp;Sandler.
 Violinist identification based on vibrato features.
 In <em>29th European Signal Processing Conference (EUSIPCO)</em>.
  EURASIP, Aug 2021.
[&nbsp;<a href="pubs2021_raw_bib.html#zhao2021violinistfeatures">bib</a>&nbsp;| 
<a href="https://eusipco2021.org/">http</a>&nbsp;]

</dd>
</dl><hr><p><em>This file was generated by
<a href="http://www.lri.fr/~filliatr/bibtex2html/">bibtex2html</a> 1.96.</em></p>
