
<!-- This document was automatically generated with bibtex2html 1.99
     (see http://www.lri.fr/~filliatr/bibtex2html/),
     with the following command:
     bibtex2html -nodoc -dl -a -noabstract -nokeywords -o pubs2020_raw publications_bibtex/pubs2020.bib  -->


<dl>

<dt>
[<a name="bianco2020longtermhumans">1</a>]
</dt>
<dd>
R&nbsp;Bianco, PMC Harrison, M&nbsp;Hu, C&nbsp;Bolger, S&nbsp;Picken, MT&nbsp;Pearce, and M&nbsp;Chait.
 Long-term implicit memory for sequential auditory patterns in humans.
 <em>eLife</em>, 9:1--6, May 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#bianco2020longtermhumans">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.7554/eLife.56073">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="chettri2020deepverification">2</a>]
</dt>
<dd>
B&nbsp;Chettri, T&nbsp;Kinnunen, and E&nbsp;Benetos.
 Deep generative variational autoencoding for replay spoof detection
  in automatic speaker verification.
 <em>Computer Speech and Language</em>, 63(101092), Sep 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#chettri2020deepverification">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.csl.2020.101092">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="chettri2020subbandverification">3</a>]
</dt>
<dd>
B&nbsp;Chettri, T&nbsp;Kinnunen, and E&nbsp;Benetos.
 Subband modeling for spoofing detection in automatic speaker
  verification.
 In <em>http://www.odyssey2020.org/</em>, pages 341--348. Tokyo, Japan,
  ISCA, Nov 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#chettri2020subbandverification">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Odyssey.2020-48">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="clemente2020aassessments">4</a>]
</dt>
<dd>
A&nbsp;Clemente, M&nbsp;Vila-Vidal, MT&nbsp;Pearce, G&nbsp;Aguiló, G&nbsp;Corradi, and M&nbsp;Nadal.
 A set of 200 musical stimuli varying in balance, contour, symmetry,
  and complexity: Behavioral and computational assessments.
 <em>Behavioral Research Methods</em>, Feb 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#clemente2020aassessments">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.3758/s13428-019-01329-8">DOI</a>&nbsp;| 
<a href="https://www.ncbi.nlm.nih.gov/pubmed/32052354">http</a>&nbsp;]

</dd>


<dt>
[<a name="delgadoluezas2020spectralsounds">5</a>]
</dt>
<dd>
A&nbsp;Delgado&nbsp;Luezas, C&nbsp;Saitis, and M&nbsp;Sandler.
 Spectral and temporal timbral cues of vocal imitations of drum
  sounds.
 Sep 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#delgadoluezas2020spectralsounds">bib</a>&nbsp;]

</dd>


<dt>
[<a name="demirel2020automaticselfattention">6</a>]
</dt>
<dd>
E&nbsp;Demirel, S&nbsp;Ahlback, and S&nbsp;DIxon.
 Automatic lyrics transcription using dilated convolutional neural
  networks with self-attention.
 In <em>Proceedings of the International Joint Conference on Neural
  Networks</em>, Jul 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#demirel2020automaticselfattention">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/IJCNN48605.2020.9207052">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="edlin2020exploringmaterial">7</a>]
</dt>
<dd>
L&nbsp;Edlin, Y&nbsp;Liu, N&nbsp;Bryan-Kinns, and J&nbsp;Reiss.
 Exploring augmented reality as craft material.
 volume 12428 LNCS, pages 54--69. Jan 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#edlin2020exploringmaterial">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/978-3-030-59990-4_5">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="fanoyela2020onlinetree">8</a>]
</dt>
<dd>
D&nbsp;Fano&nbsp;Yela, F&nbsp;Thalmann, V&nbsp;Nicosia, D&nbsp;Stowell, and M&nbsp;Sandler.
 Online visibility graphs: Encoding visibility in a binary search
  tree.
 <em>Physical Review Research</em>, 2(2), Apr 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#fanoyela2020onlinetree">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1103/physrevresearch.2.023069">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="fields2020prefacepreface">9</a>]
</dt>
<dd>
B&nbsp;Fields, T&nbsp;Stockman, LV&nbsp;Nickerson, and PGT Healey.
 Preface.
 In <em>Proceedings of the 20th BCS HCI Group Conference: Engage, HCI
  2006</em>, page&nbsp;i, Jan 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#fields2020prefacepreface">bib</a>&nbsp;]

</dd>


<dt>
[<a name="gregoromichelaki2020completabilityincompleteness">10</a>]
</dt>
<dd>
E&nbsp;Gregoromichelaki, G&nbsp;Mills, C&nbsp;Howes, A&nbsp;Eshghi, S&nbsp;Chatzikyriakidis, M&nbsp;Purver,
  R&nbsp;Kempson, R&nbsp;Cann, and P&nbsp;Healey.
 Completability vs (in)completeness.
 <em>Acta Linguistica Hafniensia</em>, Oct 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#gregoromichelaki2020completabilityincompleteness">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1080/03740463.2020.1795549">DOI</a>&nbsp;| 
<a href="https://www.tandfonline.com/doi/full/10.1080/03740463.2020.1795549?instName=Queen+Mary\%2C+University+of+London">http</a>&nbsp;]

</dd>


<dt>
[<a name="hanlon2020theextractor">11</a>]
</dt>
<dd>
KO&nbsp;Hanlon and MB&nbsp;Sandler.
 The fifthnet chroma extractor.
 In <em>ICASSP, IEEE International Conference on Acoustics, Speech
  and Signal Processing - Proceedings</em>, volume 2020-May, pages 3752--3756, May
  2020.
[&nbsp;<a href="pubs2020_raw_bib.html#hanlon2020theextractor">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP40776.2020.9053714">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="harrison2020aleadings">12</a>]
</dt>
<dd>
PMC Harrison and MT&nbsp;Pearce.
 A computational cognitive model for the analysis and generation of
  voice leadings.
 <em>Music Perception</em>, 37(3):208--224, Feb 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#harrison2020aleadings">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1525/MP.2020.37.3.208">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="hu2020tdcsos">13</a>]
</dt>
<dd>
W&nbsp;Hu, T&nbsp;Ma, Y&nbsp;Wang, F&nbsp;Xu, and J&nbsp;Reiss.
 Tdcs: a new scheduling framework for real-time multimedia os.
 <em>International Journal of Parallel, Emergent and Distributed
  Systems</em>, 35(3):396--411, May 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#hu2020tdcsos">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1080/17445760.2018.1539717">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="Kim2020">14</a>]
</dt>
<dd>
R&nbsp;Kim, S&nbsp;Thomas, RV&nbsp;Dierendonck, N&nbsp;Bryan-Kinns, and S&nbsp;Poslad.
 Working with nature's lag: Initial design lessons for slow biotic
  games.
 In GN&nbsp;Yannakakis, A&nbsp;Liapis, P&nbsp;Kyburz, V&nbsp;Volz, F&nbsp;Khosmood, and
  P&nbsp;Lopes, editors, <em>FDG</em>, pages 29:1--29:1. ACM, 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#Kim2020">bib</a>&nbsp;| 
<a href="https://doi.org/10.1145/3402942">http</a>&nbsp;]

</dd>


<dt>
[<a name="kim2020workinggames">15</a>]
</dt>
<dd>
R&nbsp;Kim, S&nbsp;Thomas, R&nbsp;Van&nbsp;Dierendonck, N&nbsp;Bryan-Kinns, and S&nbsp;Poslad.
 Working with nature's lag: Initial design lessons for slow biotic
  games.
 In <em>ACM International Conference Proceeding Series</em>, Sep 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#kim2020workinggames">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3402942.3409790">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="kudumakis2020theblockchains">16</a>]
</dt>
<dd>
P&nbsp;KUDUMAKIS, T&nbsp;WILMERING, M&nbsp;Sandler, V&nbsp;Rodríguez-Doncel, L&nbsp;Boch, and
  J&nbsp;Delgado.
 The challenge: From mpeg intellectual property rights ontologies to
  smart contracts and blockchains.
 <em>IEEE: Signal Processing Magazine</em>, 37(2):89--95, Feb 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#kudumakis2020theblockchains">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/MSP.2019.2955207">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="lau2020howcontext">17</a>]
</dt>
<dd>
JH&nbsp;Lau, CS&nbsp;Armendariz, S&nbsp;Lappin, M&nbsp;Purver, and C&nbsp;Shu.
 How furiously can colourless green ideas sleep? sentence
  acceptability in context.
 <em>Trans. Assoc. Comput. Linguistics</em>, 8:296--310, Jun 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#lau2020howcontext">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1162/tacl_a_00315">DOI</a>&nbsp;| 
<a href="https://www.mitpressjournals.org/doi/full/10.1162/tacl_a_00315">http</a>&nbsp;]

</dd>


<dt>
[<a name="Lau2020">18</a>]
</dt>
<dd>
JH&nbsp;Lau, C&nbsp;Santos&nbsp;Armendariz, S&nbsp;Lappin, M&nbsp;Purver, and C&nbsp;Shu.
 How furiously can colourless green ideas sleep? sentence
  acceptability in context.
 <em>Transactions of the Association for Computational Linguistics</em>,
  8:296--310, Jun 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#Lau2020">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1162/tacl_a_00315">DOI</a>&nbsp;| 
<a href="http://www.eecs.qmul.ac.uk/~mpurver/papers/lau-et-al20tacl.pdf">.pdf</a>&nbsp;]

</dd>


<dt>
[<a name="lee2020realtimeapplause">19</a>]
</dt>
<dd>
JRR Lee and JD&nbsp;Reiss.
 Real-time sound synthesis of audience applause.
 <em>AES: Journal of the Audio Engineering Society</em>, 68(5):261--272,
  May 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#lee2020realtimeapplause">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.17743/JAES.2020.0025">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="lepri2020uselesspractice">20</a>]
</dt>
<dd>
G&nbsp;Lepri, A&nbsp;Mcpherson, and J&nbsp;Bowers.
 Useless, not worthless: Absurd making as critical practice.
 In <em>DIS 2020 - Proceedings of the 2020 ACM Designing Interactive
  Systems Conference</em>, pages 1887--1899, Jul 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#lepri2020uselesspractice">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3357236.3395547">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="light2020designingnotquiteyet">21</a>]
</dt>
<dd>
A&nbsp;Light, PGT Healey, and G&nbsp;Simpson.
 Designing the not-quite-yet.
 In <em>Proceedings of the 20th BCS HCI Group Conference: Engage, HCI
  2006</em>, pages 282--283, Jan 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#light2020designingnotquiteyet">bib</a>&nbsp;]

</dd>


<dt>
[<a name="marinelli2020musicalspectra">22</a>]
</dt>
<dd>
L&nbsp;Marinelli, A&nbsp;Lykartsis, S&nbsp;Weinzierl, and C&nbsp;Saitis.
 Musical dynamics classification with cnn and modulation spectra.
 Torino, Aug 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#marinelli2020musicalspectra">bib</a>&nbsp;]

</dd>


<dt>
[<a name="martinezramirez2020deepeffects">23</a>]
</dt>
<dd>
M&nbsp;Martinez&nbsp;Ramirez, E&nbsp;Benetos, and J&nbsp;Reiss.
 Deep learning for black-box modeling of audio effects.
 <em>Applied Sciences</em>, 10(2), Jan 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#martinezramirez2020deepeffects">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.3390/app10020638">DOI</a>&nbsp;| 
<a href="https://www.mdpi.com/journal/applsci">http</a>&nbsp;]

</dd>


<dt>
[<a name="martinezramirez2020modelingnetwork">24</a>]
</dt>
<dd>
M&nbsp;Martinez&nbsp;Ramirez, E&nbsp;Benetos, and J&nbsp;Reiss.
 Modeling plate and spring reverberation using a dsp-informed deep
  neural network.
 pages 241--245. Barcelona, Spain, IEEE, May 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#martinezramirez2020modelingnetwork">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP40776.2020.9053093">DOI</a>&nbsp;| 
<a href="https://2020.ieeeicassp.org/">http</a>&nbsp;]

</dd>


<dt>
[<a name="mcpherson2020beholdeninstruments">25</a>]
</dt>
<dd>
A&nbsp;Mcpherson and G&nbsp;Lepri.
 Beholden to our tools: Negotiating with technology while sketching
  digital instruments.
 Jun 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#mcpherson2020beholdeninstruments">bib</a>&nbsp;]

</dd>


<dt>
[<a name="metzig2020classificationtunes">26</a>]
</dt>
<dd>
C&nbsp;Metzig, M&nbsp;Gould, R&nbsp;Noronha, R&nbsp;Abbey, M&nbsp;Sandler, and C&nbsp;Colijn.
 Classification of origin with feature selection and network
  construction for folk tunes.
 <em>Pattern Recognition Letters</em>, 133:356--364, May 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#metzig2020classificationtunes">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.patrec.2020.03.023">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="mishra2020reliablelistening">27</a>]
</dt>
<dd>
S&nbsp;MISHRA, E&nbsp;Benetos, B&nbsp;Sturm, and S&nbsp;Dixon.
 Reliable local explanations for machine listening.
 Glasgow, UK, IEEE, Jul 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#mishra2020reliablelistening">bib</a>&nbsp;| 
<a href="https://wcci2020.org/">http</a>&nbsp;]

</dd>


<dt>
[<a name="moro2020ageneration">28</a>]
</dt>
<dd>
G&nbsp;Moro and A&nbsp;Mcpherson.
 A platform for low-latency continuous keyboard sensing and sound
  generation.
 In <em>nime.org/archives</em>. Royal Birmingham Conservatoire, Jul 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#moro2020ageneration">bib</a>&nbsp;]

</dd>


<dt>
[<a name="oconnor2020perceptualspacesvoice">29</a>]
</dt>
<dd>
Brendan O’Connor, Simon Dixon, and George Fazekas.
 An exploratory study on perceptual spaces of the singing voice.
 In <em>The 2020 Joint AI Conference on Music Creativity</em>,
  volume&nbsp;1, Oct 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#oconnor2020perceptualspacesvoice">bib</a>&nbsp;| 
<a href="https://boblsturm.github.io/aimusic2020/programme.html">.html</a>&nbsp;]

</dd>


<dt>
[<a name="pankajakshan2020memoryrecognition">30</a>]
</dt>
<dd>
A&nbsp;Pankajakshan, H&nbsp;Bear, V&nbsp;Subramanian, and E&nbsp;Benetos.
 Memory controlled sequential self attention for sound recognition.
 Shanghai, China, International Speech and Communication Association
  (ISCA), Oct 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#pankajakshan2020memoryrecognition">bib</a>&nbsp;]

</dd>


<dt>
[<a name="peeters2020apostproduction">31</a>]
</dt>
<dd>
GG&nbsp;Peeters and JD&nbsp;Reiss.
 A deep learning approach to sound classification for film audio
  post-production.
 In <em>148th Audio Engineering Society International Convention</em>,
  Jan 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#peeters2020apostproduction">bib</a>&nbsp;]

</dd>


<dt>
[<a name="phan2020towardslearning">32</a>]
</dt>
<dd>
H&nbsp;Phan, OY&nbsp;Chen, P&nbsp;Koch, Z&nbsp;Lu, I&nbsp;McLoughlin, A&nbsp;Mertins, and M&nbsp;De&nbsp;Vos.
 Towards more accurate automatic sleep staging via deep transfer
  learning.
 <em>IEEE Transactions on Biomedical Engineering</em>, PP, Aug 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#phan2020towardslearning">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TBME.2020.3020381">DOI</a>&nbsp;| 
<a href="https://www.ncbi.nlm.nih.gov/pubmed/32866092">http</a>&nbsp;]

</dd>


<dt>
[<a name="phan2020improvingenhancement">33</a>]
</dt>
<dd>
H&nbsp;Phan, IV&nbsp;McLoughlin, L&nbsp;Pham, OY&nbsp;Chen, P&nbsp;Koch, M&nbsp;De&nbsp;Vos, and A&nbsp;Mertins.
 Improving gans for speech enhancement.
 <em>IEEE Signal Processing Letters</em>, pages 1--1, Sep 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#phan2020improvingenhancement">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/lsp.2020.3025020">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="phan2020personalizedregularization">34</a>]
</dt>
<dd>
H&nbsp;Phan, K&nbsp;Mikkelsen, OY&nbsp;Chén, P&nbsp;Koch, A&nbsp;Mertins, P&nbsp;Kidmose, and M&nbsp;De&nbsp;Vos.
 Personalized automatic sleep staging with single-night data: a pilot
  study with kl-divergence regularization.
 <em>Physiological Measurement</em>, Jun 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#phan2020personalizedregularization">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1088/1361-6579/ab921e">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="proutskova2020fromethnomusicontology">35</a>]
</dt>
<dd>
P&nbsp;Proutskova, A&nbsp;Volk, P&nbsp;Heidarian, and G&nbsp;Fazekas.
 From music ontology towards ethno-music-ontology.
 In <em>
  https://www.ismir2020.net/assets/img/proceedings/2020_ISMIR_Proceedings.pdf</em>,
  pages 923--931. Montreal, Canada, Oct 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#proutskova2020fromethnomusicontology">bib</a>&nbsp;| 
<a href="http://semantiaudio.net/">http</a>&nbsp;]

</dd>


<dt>
[<a name="quirogamartinez2020decomposingsystem">36</a>]
</dt>
<dd>
DR&nbsp;Quiroga-Martinez, NC&nbsp;Hansen, A&nbsp;Højlund, M&nbsp;Pearce, E&nbsp;Brattico, and P&nbsp;Vuust.
 Decomposing neural responses to melodic surprise in musicians and
  non-musicians: Evidence for a hierarchy of predictions in the auditory
  system.
 <em>NeuroImage</em>, 215, Apr 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#quirogamartinez2020decomposingsystem">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.neuroimage.2020.116816">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="quirogamartinez2020musicalnonmusicians">37</a>]
</dt>
<dd>
DR&nbsp;Quiroga-Martinez, NC&nbsp;Hansen, A&nbsp;Højlund, M&nbsp;Pearce, E&nbsp;Brattico, and P&nbsp;Vuust.
 Musical prediction error responses similarly reduced by predictive
  uncertainty in musicians and non-musicians.
 <em>European Journal of Neuroscience</em>, Jan 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#quirogamartinez2020musicalnonmusicians">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1101/754333">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="ragano2020audiorepresentation">38</a>]
</dt>
<dd>
A&nbsp;Ragano, E&nbsp;Benetos, and A&nbsp;Hines.
 Audio impairment recognition using a correlation-based feature
  representation.
 In <em>http://qomex2020.ie/</em>. Athlone, Ireland, IEEE, May 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#ragano2020audiorepresentation">bib</a>&nbsp;]

</dd>


<dt>
[<a name="ragano2020developmentconditions">39</a>]
</dt>
<dd>
A&nbsp;Ragano, E&nbsp;Benetos, and A&nbsp;Hines.
 Development of a speech quality database under uncontrolled
  conditions.
 Shanghai, China, Oct 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#ragano2020developmentconditions">bib</a>&nbsp;]

</dd>


<dt>
[<a name="rohanian2020multimodalspeech">40</a>]
</dt>
<dd>
M&nbsp;Rohanian, J&nbsp;Hough, and M&nbsp;Purver.
 Multi-modal fusion with gating using audio, lexical and disfluency
  features for alzheimer’s dementia recognition from spontaneous speech.
 pages 2187--2191, Jan 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#rohanian2020multimodalspeech">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/interspeech.2020-2721">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="saitis2020brightnesscategories">41</a>]
</dt>
<dd>
C&nbsp;Saitis and K&nbsp;Siedenburg.
 Brightness perception for musical instrument sounds: Relation to
  timbre dissimilarity and source-cause categories.
 <em>The Journal of the Acoustical Society of America</em>,
  148(4):2256--2266, Oct 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#saitis2020brightnesscategories">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1121/10.0002275">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="Sarmento2020">42</a>]
</dt>
<dd>
Pedro Sarmento, Ove Holmqvist, and Mathieu Barthet.
 Musical Smart City: Perspectives on Ubiquitous Sonification.
 In <em>Proceedings of the 2020 Ubiquitous Music Workshop</em>, 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#Sarmento2020">bib</a>&nbsp;]

</dd>


<dt>
[<a name="shatri2020opticalchallenges">43</a>]
</dt>
<dd>
E&nbsp;Shatri and G&nbsp;Fazekas.
 Optical music recognition: State of the art and major challenges.
 Hamburg, May 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#shatri2020opticalchallenges">bib</a>&nbsp;| 
<a href="https://www.elonashatri.co.uk/">http</a>&nbsp;]

</dd>


<dt>
[<a name="shekhar2020automatingestonian">44</a>]
</dt>
<dd>
R&nbsp;Shekhar, M&nbsp;Pranjić, S&nbsp;Pollak, A&nbsp;Pelicon, and M&nbsp;Purver.
 Automating news comment moderation with limited resources:
  Benchmarking in croatian and estonian.
 <em>Journal of Language Technology and Computational Linguistics</em>,
  34(1):49--79, Sep 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#shekhar2020automatingestonian">bib</a>&nbsp;| 
<a href="https://jlcl.org/content/2-allissues/1-heft1-2020/jlcl_2020-1_3.pdf">.pdf</a>&nbsp;]

</dd>


<dt>
[<a name="soave2020areality">45</a>]
</dt>
<dd>
F&nbsp;Soave, N&nbsp;Bryan-Kinns, and I&nbsp;Farkhatdinov.
 A preliminary study on full-body haptic stimulation on modulating
  self-motion perception in virtual reality.
 Aug 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#soave2020areality">bib</a>&nbsp;]

</dd>


<dt>
[<a name="solomes2020efficientsystem">46</a>]
</dt>
<dd>
AM&nbsp;Solomes and D&nbsp;Stowell.
 Efficient bird sound detection on the bela embedded system.
 In <em>ICASSP, IEEE International Conference on Acoustics, Speech
  and Signal Processing - Proceedings</em>, volume 2020-May, pages 746--750, May
  2020.
[&nbsp;<a href="pubs2020_raw_bib.html#solomes2020efficientsystem">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP40776.2020.9053533">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="stockman2020exploringpriming">47</a>]
</dt>
<dd>
A&nbsp;Stockman and F&nbsp;Feng.
 Exploring crossmodal perceptual enhancement and integration in a
  sequence reproducing task with cognitive priming.
 <em>Journal on Multimodal User Interfaces</em>, Jul 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#stockman2020exploringpriming">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/s12193-020-00326-y">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="stockman2020theobjects">48</a>]
</dt>
<dd>
A&nbsp;Stockman and S&nbsp;WILKIE.
 The effect of audio cues and sound source stimuli on the perception
  of approaching objects.
 <em>Applied Acoustics</em>, May 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#stockman2020theobjects">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.apacoust.2020.107388">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="stoller2020sequnetmodelling">49</a>]
</dt>
<dd>
D&nbsp;Stoller, M&nbsp;Tian, S&nbsp;Ewert, and S&nbsp;Dixon.
 Seq-u-net: A one-dimensional causal u-net for efficient sequence
  modelling.
 pages 2893--2900, Jul 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#stoller2020sequnetmodelling">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.24963/ijcai.2020/400">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="stowell2020auk">50</a>]
</dt>
<dd>
D&nbsp;Stowell, J&nbsp;Kelly, D&nbsp;Tanner, J&nbsp;Taylor, E&nbsp;Jones, J&nbsp;Geddes, and E&nbsp;Chalstrey.
 A harmonised, high-coverage, open dataset of solar photovoltaic
  installations in the uk.
 <em>Scientific Data</em>, 7(1), Dec 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#stowell2020auk">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1038/s41597-020-00739-0">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="stowell2020ecoacousticsscale">51</a>]
</dt>
<dd>
D&nbsp;Stowell and J&nbsp;Sueur.
 Ecoacoustics: acoustic sensing for biodiversity monitoring at scale.
 <em>Remote Sensing in Ecology and Conservation</em>, 6(3):217--219, Aug
  2020.
[&nbsp;<a href="pubs2020_raw_bib.html#stowell2020ecoacousticsscale">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1002/rse2.174">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="subramanian2020aclassification">52</a>]
</dt>
<dd>
V&nbsp;SUBRAMANIAN, A&nbsp;Pankajakshan, E&nbsp;Benetos, N&nbsp;Xu, S&nbsp;McDonald, and M&nbsp;Sandler.
 A study on the transferability of adversarial attacks in sound event
  classification.
 pages 301--305. Barcelona, Spain, IEEE, May 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#subramanian2020aclassification">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP40776.2020.9054445">DOI</a>&nbsp;| 
<a href="https://2020.ieeeicassp.org/">http</a>&nbsp;]

</dd>


<dt>
[<a name="thompson2020posterdevelopers">53</a>]
</dt>
<dd>
A&nbsp;Thompson, G&nbsp;Fazekas, and G&nbsp;Wiggins.
 Poster: Programming practices among interactive audio software
  developers.
 In <em>Proceedings of IEEE Symposium on Visual Languages and
  Human-Centric Computing, VL/HCC</em>, volume 2020-August, Aug 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#thompson2020posterdevelopers">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/VL/HCC50065.2020.9127261">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="turchet2020theontology">54</a>]
</dt>
<dd>
L&nbsp;Turchet, F&nbsp;Antoniazzi, F&nbsp;Viola, F&nbsp;Giunchiglia, and G&nbsp;Fazekas.
 The internet of musical things ontology.
 <em>Journal of Web Semantics</em>, 60, Jan 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#turchet2020theontology">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.websem.2020.100548">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="turchet2020thechallenges">55</a>]
</dt>
<dd>
L&nbsp;Turchet, G&nbsp;Fazekas, M&nbsp;Lagrange, HS&nbsp;Ghadikolaei, and C&nbsp;Fischione.
 The internet of audio things: State of the art, vision, and
  challenges.
 <em>IEEE Internet of Things Journal</em>, 7(10):10233--10249, May 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#turchet2020thechallenges">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/jiot.2020.2997047">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="turchet2020cloudsmartinteractions">56</a>]
</dt>
<dd>
L&nbsp;Turchet, J&nbsp;Pauwels, C&nbsp;Fischione, and G&nbsp;Fazekas.
 Cloud-smart musical instrument interactions.
 <em>ACM Transactions on Internet of Things</em>, 1(3):1--29, Jul 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#turchet2020cloudsmartinteractions">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3377881">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="vahidi2020timbresynthesizer">57</a>]
</dt>
<dd>
C&nbsp;Vahidi, G&nbsp;Fazekas, C&nbsp;Saitis, and A&nbsp;Palladini.
 Timbre space representation of a subtractive synthesizer.
 Sep 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#vahidi2020timbresynthesizer">bib</a>&nbsp;| 
<a href="http://timbre2020.mus.auth.gr/">http</a>&nbsp;]

</dd>


<dt>
[<a name="wang2020playingscattering">58</a>]
</dt>
<dd>
C&nbsp;Wang, V&nbsp;Lostanlen, E&nbsp;Benetos, and E&nbsp;Chew.
 Playing technique recognition by joint time–frequency scattering.
 pages 881--885. Barcelona, Spain, May 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#wang2020playingscattering">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP40776.2020.9053474">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="wang2020oncultures">59</a>]
</dt>
<dd>
W&nbsp;Wang, N&nbsp;Bryan-Kinns, and JG&nbsp;Sheridan.
 On the role of in-situ making and evaluation in designing across
  cultures.
 <em>CoDesign</em>, 16(3):233--250, Jul 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#wang2020oncultures">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1080/15710882.2019.1580296">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="wei2020acrnndetection">60</a>]
</dt>
<dd>
W&nbsp;Wei, H&nbsp;Zhu, E&nbsp;Benetos, and Y&nbsp;Wang.
 A-crnn: a domain adaptation model for sound event detection.
 pages 276--280. Barcelona, Spain, IEEE, May 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#wei2020acrnndetection">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP40776.2020.9054248">DOI</a>&nbsp;| 
<a href="https://2020.ieeeicassp.org/">http</a>&nbsp;]

</dd>


<dt>
[<a name="williams2020onmusic">61</a>]
</dt>
<dd>
D&nbsp;Williams, B&nbsp;Fazenda, V&nbsp;Williamson, and G&nbsp;Fazekas.
 On performance and perceived effort in trail runners using sensor
  control to generate biosynchronous music.
 <em>Sensors (Basel, Switzerland)</em>, 20(16):1--14, Aug 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#williams2020onmusic">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.3390/s20164528">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="wilmering2020aeffects">62</a>]
</dt>
<dd>
T&nbsp;WILMERING, DJ&nbsp;MOFFAT, A&nbsp;Milo, and M&nbsp;Sandler.
 A history of audio effects.
 <em>Applied Sciences</em>, 10(3), Jan 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#wilmering2020aeffects">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.3390/app10030791">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="ycart2020learninglstms">63</a>]
</dt>
<dd>
A&nbsp;Ycart and E&nbsp;Benetos.
 Learning and evaluation methodologies for polyphonic music sequence
  prediction with lstms.
 <em>IEEE/ACM Transactions on Audio, Speech and Language Processing</em>,
  28(1):1328--1341, Dec 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#ycart2020learninglstms">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TASLP.2020.2987130">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="ycart2020investigatingtranscription">64</a>]
</dt>
<dd>
A&nbsp;Ycart, L&nbsp;Liu, E&nbsp;Benetos, and M&nbsp;Pearce.
 Investigating the perceptual validity of evaluation metrics for
  automatic piano music transcription.
 <em>Transactions of the International Society for Music Information
  Retrieval</em>, 3(1):68--81, Jun 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#ycart2020investigatingtranscription">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.5334/tismir.57">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="zioga2020auditorystyle">65</a>]
</dt>
<dd>
I&nbsp;Zioga, PMC Harrison, MT&nbsp;Pearce, J&nbsp;Bhattacharya, and CDB Luft.
 Auditory but not audiovisual cues lead to higher neural sensitivity
  to the statistical regularities of an unfamiliar musical style.
 <em>Journal of Cognitive Neuroscience</em>, 32(12):2241--2259, Jan 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#zioga2020auditorystyle">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1162/jocn_a_01614">DOI</a>&nbsp;]

</dd>
</dl><hr><p><em>This file was generated by
<a href="http://www.lri.fr/~filliatr/bibtex2html/">bibtex2html</a> 1.99.</em></p>
