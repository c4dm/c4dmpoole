
<!-- This document was automatically generated with bibtex2html 1.96
     (see http://www.lri.fr/~filliatr/bibtex2html/),
     with the following command:
     ./bibtex2html -nodoc -dl -a -noabstract -nokeywords -o pubs2020_raw pubs2020.bib  -->


<dl>

<dt>
[<a name="agrawallearningalignment">1</a>]
</dt>
<dd>
R&nbsp;Agrawal and S&nbsp;Dixon.
 Learning frame similarity using siamese networks for audio-to-score
  alignment.
 Amsterdam, The Netherlands.
[&nbsp;<a href="pubs2020_raw_bib.html#agrawallearningalignment">bib</a>&nbsp;]

</dd>


<dt>
[<a name="armendariz2020semeval2020context">2</a>]
</dt>
<dd>
CS&nbsp;Armendariz, M&nbsp;Purver, S&nbsp;Pollak, N&nbsp;Ljubesic, M&nbsp;Ulcar, I&nbsp;Vulic, and
  MT&nbsp;Pilehvar.
 Semeval-2020 task 3: Graded word similarity in context.
 In A&nbsp;Herbelot, X&nbsp;Zhu, A&nbsp;Palmer, N&nbsp;Schneider, J&nbsp;May, and E&nbsp;Shutova,
  editors, <em>SemEval@COLING</em>, pages 36-49. International Committee for
  Computational Linguistics, 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#armendariz2020semeval2020context">bib</a>&nbsp;| 
<a href="https://aclanthology.org/volumes/2020.semeval-1/">http</a>&nbsp;]

</dd>


<dt>
[<a name="armendarizcosimlexcontext">3</a>]
</dt>
<dd>
CS&nbsp;Armendariz, M&nbsp;Purver, M&nbsp;Ulčar, S&nbsp;Pollak, N&nbsp;Ljubešić, M&nbsp;Robnik-Šikonja,
  M&nbsp;Granroth-Wilding, and K&nbsp;Vaik.
 Cosimlex: A resource for evaluating graded word similarity in
  context.
 Marseille.
[&nbsp;<a href="pubs2020_raw_bib.html#armendarizcosimlexcontext">bib</a>&nbsp;| 
<a href="http://www.eecs.qmul.ac.uk/~mpurver/papers/armendariz-et-al20lrec.pdf">.pdf</a>&nbsp;]

</dd>


<dt>
[<a name="bahameish2020fundamentalsystems">4</a>]
</dt>
<dd>
M&nbsp;Bahameish and T&nbsp;Stockman.
 Fundamental considerations of hrv analysis in the development of
  real-time biofeedback systems.
 In <em>Computing in Cardiology</em>, volume 2020-September, Sep 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#bahameish2020fundamentalsystems">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.22489/CinC.2020.078">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="banluesombatkul2020metasleeplearnermetalearning">5</a>]
</dt>
<dd>
N&nbsp;Banluesombatkul, P&nbsp;Ouppaphan, P&nbsp;Leelaarporn, P&nbsp;Lakhan, B&nbsp;Chaitusaney,
  N&nbsp;Jaimchariya, E&nbsp;Chuangsuwanich, W&nbsp;Chen, H&nbsp;Phan, N&nbsp;Dilokthanakul, and
  T&nbsp;Wilaiprasitporn.
 Metasleeplearner: A pilot study on fast adaptation of
  bio-signals-based sleep stage classifier to new individual subject using
  meta-learning.
 <em>IEEE Journal of Biomedical and Health Informatics</em>, PP, Nov
  2020.
[&nbsp;<a href="pubs2020_raw_bib.html#banluesombatkul2020metasleeplearnermetalearning">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/JBHI.2020.3037693">DOI</a>&nbsp;| 
<a href="https://www.ncbi.nlm.nih.gov/pubmed/33180737">http</a>&nbsp;]

</dd>


<dt>
[<a name="bianco2020longtermhumans">6</a>]
</dt>
<dd>
R&nbsp;Bianco, PMC Harrison, M&nbsp;Hu, C&nbsp;Bolger, S&nbsp;Picken, MT&nbsp;Pearce, and M&nbsp;Chait.
 Long-term implicit memory for sequential auditory patterns in humans.
 <em>eLife</em>, 9:1-6, May 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#bianco2020longtermhumans">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.7554/eLife.56073">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="bryce2020thereality">7</a>]
</dt>
<dd>
L&nbsp;Bryce, M&nbsp;Sandler, S&nbsp;Serafin, and L&nbsp;Andersen.
 The sense of auditory presence in a choir for virtual reality.
 New York, Oct 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#bryce2020thereality">bib</a>&nbsp;]

</dd>


<dt>
[<a name="chen2020buildingsmartphones">8</a>]
</dt>
<dd>
O&nbsp;Chen, F&nbsp;Lipsmeier, H&nbsp;Phan, J&nbsp;Prince, K&nbsp;Taylor, C&nbsp;Gossens, M&nbsp;Lindemann, and
  M&nbsp;De&nbsp;Vos.
 Building a machine-learning framework to remotely assess parkinson's
  disease using smartphones.
 <em>IEEE Transactions on Biomedical Engineering</em>, pages 1-1, Apr
  2020.
[&nbsp;<a href="pubs2020_raw_bib.html#chen2020buildingsmartphones">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/tbme.2020.2988942">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="chettri2020datasetbenchmark">9</a>]
</dt>
<dd>
B&nbsp;Chettri, E&nbsp;Benetos, and BLT Sturm.
 Dataset artefacts in anti-spoofing systems: a case study on the
  asvspoof 2017 benchmark.
 <em>IEEE/ACM Transactions on Audio, Speech and Language Processing</em>,
  28:3018-3028, Nov 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#chettri2020datasetbenchmark">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TASLP.2020.3036777">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="chettri2020deepverification">10</a>]
</dt>
<dd>
B&nbsp;Chettri, T&nbsp;Kinnunen, and E&nbsp;Benetos.
 Deep generative variational autoencoding for replay spoof detection
  in automatic speaker verification.
 <em>Computer Speech and Language</em>, 63(101092), Sep 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#chettri2020deepverification">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.csl.2020.101092">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="chettri2020subbandverification">11</a>]
</dt>
<dd>
B&nbsp;Chettri, T&nbsp;Kinnunen, and E&nbsp;Benetos.
 Subband modeling for spoofing detection in automatic speaker
  verification.
 In <em>http://www.odyssey2020.org/</em>, pages 341-348. Tokyo, Japan,
  ISCA, Nov 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#chettri2020subbandverification">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Odyssey.2020-48">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="clemente2020aassessments">12</a>]
</dt>
<dd>
A&nbsp;Clemente, M&nbsp;Vila-Vidal, MT&nbsp;Pearce, G&nbsp;Aguiló, G&nbsp;Corradi, and M&nbsp;Nadal.
 A set of 200 musical stimuli varying in balance, contour, symmetry,
  and complexity: Behavioral and computational assessments.
 <em>Behavioral Research Methods</em>, Feb 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#clemente2020aassessments">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.3758/s13428-019-01329-8">DOI</a>&nbsp;| 
<a href="https://www.ncbi.nlm.nih.gov/pubmed/32052354">http</a>&nbsp;]

</dd>


<dt>
[<a name="delgadoluezas2020spectralsounds">13</a>]
</dt>
<dd>
A&nbsp;Delgado&nbsp;Luezas, C&nbsp;Saitis, and M&nbsp;Sandler.
 Spectral and temporal timbral cues of vocal imitations of drum
  sounds.
 Sep 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#delgadoluezas2020spectralsounds">bib</a>&nbsp;]

</dd>


<dt>
[<a name="demirel2020automaticselfattention">14</a>]
</dt>
<dd>
E&nbsp;Demirel, S&nbsp;Ahlback, and S&nbsp;DIxon.
 Automatic lyrics transcription using dilated convolutional neural
  networks with self-attention.
 In <em>Proceedings of the International Joint Conference on Neural
  Networks</em>, Jul 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#demirel2020automaticselfattention">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/IJCNN48605.2020.9207052">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="edlin2020exploringmaterial">15</a>]
</dt>
<dd>
L&nbsp;Edlin, Y&nbsp;Liu, N&nbsp;Bryan-Kinns, and J&nbsp;Reiss.
 Exploring augmented reality as craft material.
 volume 12428 LNCS, pages 54-69. Jan 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#edlin2020exploringmaterial">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/978-3-030-59990-4_5">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="fanoyela2020onlinetree">16</a>]
</dt>
<dd>
D&nbsp;Fano&nbsp;Yela, F&nbsp;Thalmann, V&nbsp;Nicosia, D&nbsp;Stowell, and M&nbsp;Sandler.
 Online visibility graphs: Encoding visibility in a binary search
  tree.
 <em>Physical Review Research</em>, 2(2), Apr 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#fanoyela2020onlinetree">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1103/physrevresearch.2.023069">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="fields2020prefacepreface">17</a>]
</dt>
<dd>
B&nbsp;Fields, T&nbsp;Stockman, LV&nbsp;Nickerson, and PGT Healey.
 Preface.
 In <em>Proceedings of the 20th BCS HCI Group Conference: Engage, HCI
  2006</em>, page&nbsp;i, Jan 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#fields2020prefacepreface">bib</a>&nbsp;]

</dd>


<dt>
[<a name="gan2020amodels">18</a>]
</dt>
<dd>
Y&nbsp;Gan, M&nbsp;Purver, and JR&nbsp;Woodward.
 A review of cross-domain text-to-sql models.
 In B&nbsp;Shmueli and YJ&nbsp;Huang, editors, <em>AACL/IJCNLP (Student
  Research Workshop)</em>, pages 108-115. Association for Computational
  Linguistics, 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#gan2020amodels">bib</a>&nbsp;| 
<a href="https://aclanthology.org/volumes/2020.aacl-srw/">http</a>&nbsp;]

</dd>


<dt>
[<a name="gregoromichelaki2020completabilityincompleteness">19</a>]
</dt>
<dd>
E&nbsp;Gregoromichelaki, G&nbsp;Mills, C&nbsp;Howes, A&nbsp;Eshghi, S&nbsp;Chatzikyriakidis, M&nbsp;Purver,
  R&nbsp;Kempson, R&nbsp;Cann, and P&nbsp;Healey.
 Completability vs (in)completeness.
 <em>Acta Linguistica Hafniensia</em>, Oct 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#gregoromichelaki2020completabilityincompleteness">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1080/03740463.2020.1795549">DOI</a>&nbsp;| 
<a href="https://www.tandfonline.com/doi/full/10.1080/03740463.2020.1795549?instName=Queen+Mary\%2C+University+of+London">http</a>&nbsp;]

</dd>


<dt>
[<a name="hanlon2020theextractor">20</a>]
</dt>
<dd>
KO&nbsp;Hanlon and MB&nbsp;Sandler.
 The fifthnet chroma extractor.
 In <em>ICASSP, IEEE International Conference on Acoustics, Speech
  and Signal Processing - Proceedings</em>, volume 2020-May, pages 3752-3756, May
  2020.
[&nbsp;<a href="pubs2020_raw_bib.html#hanlon2020theextractor">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP40776.2020.9053714">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="harrison2020ppmdecaydecay">21</a>]
</dt>
<dd>
PMC Harrison, R&nbsp;Bianco, M&nbsp;Chait, and MT&nbsp;Pearce.
 Ppm-decay: A computational model of auditory prediction with memory
  decay.
 <em>PLoS Computational Biology</em>, 16(11), Nov 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#harrison2020ppmdecaydecay">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1371/journal.pcbi.1008304">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="harrison2020aleadings">22</a>]
</dt>
<dd>
PMC Harrison and MT&nbsp;Pearce.
 A computational cognitive model for the analysis and generation of
  voice leadings.
 <em>Music Perception</em>, 37(3):208-224, Feb 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#harrison2020aleadings">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1525/MP.2020.37.3.208">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="hu2020tdcsos">23</a>]
</dt>
<dd>
W&nbsp;Hu, T&nbsp;Ma, Y&nbsp;Wang, F&nbsp;Xu, and J&nbsp;Reiss.
 Tdcs: a new scheduling framework for real-time multimedia os.
 <em>International Journal of Parallel, Emergent and Distributed
  Systems</em>, 35(3):396-411, May 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#hu2020tdcsos">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1080/17445760.2018.1539717">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="kim2020workinggames">24</a>]
</dt>
<dd>
R&nbsp;Kim, S&nbsp;Thomas, RV&nbsp;Dierendonck, N&nbsp;Bryan-Kinns, and S&nbsp;Poslad.
 Working with nature's lag: Initial design lessons for slow biotic
  games.
 In GN&nbsp;Yannakakis, A&nbsp;Liapis, P&nbsp;Kyburz, V&nbsp;Volz, F&nbsp;Khosmood, and
  P&nbsp;Lopes, editors, <em>FDG</em>, pages 29:1-29:1. ACM, 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#kim2020workinggames">bib</a>&nbsp;| 
<a href="https://doi.org/10.1145/3402942">http</a>&nbsp;]

</dd>


<dt>
[<a name="kudumakis2020theblockchains">25</a>]
</dt>
<dd>
P&nbsp;KUDUMAKIS, T&nbsp;WILMERING, M&nbsp;Sandler, V&nbsp;Rodríguez-Doncel, L&nbsp;Boch, and
  J&nbsp;Delgado.
 The challenge: From mpeg intellectual property rights ontologies to
  smart contracts and blockchains.
 <em>IEEE: Signal Processing Magazine</em>, 37(2):89-95, Feb 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#kudumakis2020theblockchains">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/MSP.2019.2955207">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="lau2020howcontext">26</a>]
</dt>
<dd>
JH&nbsp;Lau, C&nbsp;Santos&nbsp;Armendariz, S&nbsp;Lappin, M&nbsp;Purver, and C&nbsp;Shu.
 How furiously can colourless green ideas sleep? sentence
  acceptability in context.
 <em>Transactions of the Association for Computational Linguistics</em>,
  8:296-310, Jun 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#lau2020howcontext">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1162/tacl_a_00315">DOI</a>&nbsp;| 
<a href="http://www.eecs.qmul.ac.uk/~mpurver/papers/lau-et-al20tacl.pdf">.pdf</a>&nbsp;]

</dd>


<dt>
[<a name="lee2020realtimeapplause">27</a>]
</dt>
<dd>
J&nbsp;Lee and J&nbsp;Reiss.
 Real-time sound synthesis of audience applause.
 <em>Journal of the Audio Engineering Society</em>, 68(4):261-272, May
  2020.
[&nbsp;<a href="pubs2020_raw_bib.html#lee2020realtimeapplause">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.17743/jaes.2020.0006">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="lepri2020uselesspractice">28</a>]
</dt>
<dd>
G&nbsp;Lepri, A&nbsp;Mcpherson, and J&nbsp;Bowers.
 Useless, not worthless: Absurd making as critical practice.
 In <em>DIS 2020 - Proceedings of the 2020 ACM Designing Interactive
  Systems Conference</em>, pages 1887-1899, Jul 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#lepri2020uselesspractice">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3357236.3395547">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="lepri2020playnime">29</a>]
</dt>
<dd>
G&nbsp;Lepri, A&nbsp;Mcpherson, A&nbsp;Nonnis, P&nbsp;Stapleton, K&nbsp;Andersen, T&nbsp;Mudd, J&nbsp;Bowers,
  P&nbsp;Bennett, and S&nbsp;Topley.
 Play make believe: Exploring design fiction and absurd making for
  critical nime.
 Jul 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#lepri2020playnime">bib</a>&nbsp;| 
<a href="http://instrumentslab.org/data/giacomo/NIME2020Workshop.pdf">.pdf</a>&nbsp;]

</dd>


<dt>
[<a name="light2020designingnotquiteyet">30</a>]
</dt>
<dd>
A&nbsp;Light, PGT Healey, and G&nbsp;Simpson.
 Designing the not-quite-yet.
 In <em>Proceedings of the 20th BCS HCI Group Conference: Engage, HCI
  2006</em>, pages 282-283, Jan 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#light2020designingnotquiteyet">bib</a>&nbsp;]

</dd>


<dt>
[<a name="liu2020dmrn152020">31</a>]
</dt>
<dd>
L&nbsp;Liu, A&nbsp;McLeod, S&nbsp;Sarkar, G&nbsp;Coleman, G&nbsp;Ruiz-Marcos, B&nbsp;Hayes, J&nbsp;Hentschel,
  D&nbsp;Shakespeare, I&nbsp;Harris, C&nbsp;Steinmetz, A&nbsp;Ragano, L&nbsp;Jovanovska, and X&nbsp;Li.
 Dmrn+15: Digital music research network workshop proceedings 2020.
 Online conference., Centre for Digital Music (C4DM), Dec 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#liu2020dmrn152020">bib</a>&nbsp;| 
<a href="https://qmro.qmul.ac.uk/xmlui/handle/123456789/2885">http</a>&nbsp;]

</dd>


<dt>
[<a name="liu2020jointmusic">32</a>]
</dt>
<dd>
L&nbsp;Liu, G-V Morfi, and E&nbsp;Benetos.
 Joint piano-roll and score transcription for polyphonic piano music.
 London, UK, Dec 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#liu2020jointmusic">bib</a>&nbsp;| 
<a href="https://cheriell.github.io/">http</a>&nbsp;]

</dd>


<dt>
[<a name="marinelli2020musicalspectra">33</a>]
</dt>
<dd>
L&nbsp;Marinelli, A&nbsp;Lykartsis, S&nbsp;Weinzierl, and C&nbsp;Saitis.
 Musical dynamics classification with cnn and modulation spectra.
 Torino, Aug 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#marinelli2020musicalspectra">bib</a>&nbsp;]

</dd>


<dt>
[<a name="martellonipercussivestudy">34</a>]
</dt>
<dd>
A&nbsp;Martelloni, A&nbsp;Mcpherson, and M&nbsp;Barthet.
 Percussive fingerstyle guitar through the lens of nime: an interview
  study.
 Royal Birmingham Conservatoire.
[&nbsp;<a href="pubs2020_raw_bib.html#martellonipercussivestudy">bib</a>&nbsp;]

</dd>


<dt>
[<a name="martinezramirez2020deepeffects">35</a>]
</dt>
<dd>
M&nbsp;Martinez&nbsp;Ramirez, E&nbsp;Benetos, and J&nbsp;Reiss.
 Deep learning for black-box modeling of audio effects.
 <em>Applied Sciences</em>, 10(2), Jan 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#martinezramirez2020deepeffects">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.3390/app10020638">DOI</a>&nbsp;| 
<a href="https://www.mdpi.com/journal/applsci">http</a>&nbsp;]

</dd>


<dt>
[<a name="martinezramirez2020modelingnetwork">36</a>]
</dt>
<dd>
M&nbsp;Martinez&nbsp;Ramirez, E&nbsp;Benetos, and J&nbsp;Reiss.
 Modeling plate and spring reverberation using a dsp-informed deep
  neural network.
 pages 241-245. Barcelona, Spain, IEEE, May 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#martinezramirez2020modelingnetwork">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP40776.2020.9053093">DOI</a>&nbsp;| 
<a href="https://2020.ieeeicassp.org/">http</a>&nbsp;]

</dd>


<dt>
[<a name="mcgregor2020metaphorsemantics">37</a>]
</dt>
<dd>
S&nbsp;McGregor, M&nbsp;Purver, and G&nbsp;Wiggins.
 Metaphor generation through context sensitive distributional
  semantics.
 In <em>Producing Figurative Expression</em>, volume&nbsp;10, pages 419-448.
  Nov 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#mcgregor2020metaphorsemantics">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1075/ftl.10.15mcg">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="mcpherson2020beholdeninstruments">38</a>]
</dt>
<dd>
A&nbsp;Mcpherson and G&nbsp;Lepri.
 Beholden to our tools: Negotiating with technology while sketching
  digital instruments.
 Jun 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#mcpherson2020beholdeninstruments">bib</a>&nbsp;]

</dd>


<dt>
[<a name="mcphersonidiomaticlanguages">39</a>]
</dt>
<dd>
A&nbsp;Mcpherson and K&nbsp;Tahiroglu.
 Idiomatic patterns and aesthetic influence in computer music
  languages.
 <em>Organised Sound: an international journal of music and
  technology</em>, 25(1).
[&nbsp;<a href="pubs2020_raw_bib.html#mcphersonidiomaticlanguages">bib</a>&nbsp;]

</dd>


<dt>
[<a name="metzig2020classificationtunes">40</a>]
</dt>
<dd>
C&nbsp;Metzig, M&nbsp;Gould, R&nbsp;Noronha, R&nbsp;Abbey, M&nbsp;Sandler, and C&nbsp;Colijn.
 Classification of origin with feature selection and network
  construction for folk tunes.
 <em>Pattern Recognition Letters</em>, 133:356-364, May 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#metzig2020classificationtunes">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.patrec.2020.03.023">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="mishra2020reliablelistening">41</a>]
</dt>
<dd>
S&nbsp;MISHRA, E&nbsp;Benetos, B&nbsp;Sturm, and S&nbsp;Dixon.
 Reliable local explanations for machine listening.
 Glasgow, UK, IEEE, Jul 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#mishra2020reliablelistening">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/IJCNN48605.2020.9207444">DOI</a>&nbsp;| 
<a href="https://wcci2020.org/">http</a>&nbsp;]

</dd>


<dt>
[<a name="moro2020ageneration">42</a>]
</dt>
<dd>
G&nbsp;Moro and A&nbsp;Mcpherson.
 A platform for low-latency continuous keyboard sensing and sound
  generation.
 In <em>nime.org/archives</em>. Royal Birmingham Conservatoire, Jul 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#moro2020ageneration">bib</a>&nbsp;]

</dd>


<dt>
[<a name="mourgela2020investigationproduction">43</a>]
</dt>
<dd>
A&nbsp;Mourgela, TR&nbsp;Agus, and JD&nbsp;Reiss.
 Investigation of a real-time hearing loss simulation for use in audio
  production.
 In <em>149th Audio Engineering Society Convention 2020, AES 2020</em>,
  Jan 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#mourgela2020investigationproduction">bib</a>&nbsp;]

</dd>


<dt>
[<a name="nguyen2020ondiffraction">44</a>]
</dt>
<dd>
V-D Nguyen, H&nbsp;Phan, A&nbsp;Mansour, A&nbsp;Coatanhay, and T&nbsp;Marsault.
 On the proof of recursive vogler algorithm for multiple knife-edge
  diffraction.
 <em>IEEE Transactions on Antennas and Propagation</em>, pages 1-1, Nov
  2020.
[&nbsp;<a href="pubs2020_raw_bib.html#nguyen2020ondiffraction">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/tap.2020.3037748">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="oconnor2020anvoice">45</a>]
</dt>
<dd>
B&nbsp;O'Connor, S&nbsp;Dixon, and G&nbsp;Fazekas.
 An exploratory study on perceptual spaces of the singing voice.
 volume&nbsp;1, Stockholm, Sweden, Oct 2020. Proceedings of the 2020 Joint
  Conference on AI Creativity.
[&nbsp;<a href="pubs2020_raw_bib.html#oconnor2020anvoice">bib</a>&nbsp;| 
<a href="http://github.com/Trebolium">http</a>&nbsp;]

</dd>


<dt>
[<a name="pankajakshan2020memoryrecognition">46</a>]
</dt>
<dd>
A&nbsp;Pankajakshan, H&nbsp;Bear, V&nbsp;Subramanian, and E&nbsp;Benetos.
 Memory controlled sequential self attention for sound recognition.
 Shanghai, China, International Speech and Communication Association
  (ISCA), Oct 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#pankajakshan2020memoryrecognition">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Interspeech.2020-1953">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="peeters2020apostproduction">47</a>]
</dt>
<dd>
GG&nbsp;Peeters and JD&nbsp;Reiss.
 A deep learning approach to sound classification for film audio
  post-production.
 In <em>148th Audio Engineering Society International Convention</em>,
  Jan 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#peeters2020apostproduction">bib</a>&nbsp;]

</dd>


<dt>
[<a name="pham2020robustframework">48</a>]
</dt>
<dd>
L&nbsp;Pham, H&nbsp;Phan, T&nbsp;Nguyen, R&nbsp;Palaniappan, A&nbsp;Mertins, and I&nbsp;McLoughlin.
 Robust acoustic scene classification using a multi-spectrogram
  encoder-decoder framework.
 <em>Digital Signal Processing</em>, pages 102943-102943, Dec 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#pham2020robustframework">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.dsp.2020.102943">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="phan2020towardslearning">49</a>]
</dt>
<dd>
H&nbsp;Phan, OY&nbsp;Chen, P&nbsp;Koch, Z&nbsp;Lu, I&nbsp;McLoughlin, A&nbsp;Mertins, and M&nbsp;De&nbsp;Vos.
 Towards more accurate automatic sleep staging via deep transfer
  learning.
 <em>IEEE Transactions on Biomedical Engineering</em>, PP, Aug 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#phan2020towardslearning">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TBME.2020.3020381">DOI</a>&nbsp;| 
<a href="https://www.ncbi.nlm.nih.gov/pubmed/32866092">http</a>&nbsp;]

</dd>


<dt>
[<a name="phan2020improvingenhancement">50</a>]
</dt>
<dd>
H&nbsp;Phan, IV&nbsp;McLoughlin, L&nbsp;Pham, OY&nbsp;Chen, P&nbsp;Koch, M&nbsp;De&nbsp;Vos, and A&nbsp;Mertins.
 Improving gans for speech enhancement.
 <em>IEEE Signal Processing Letters</em>, 27:1700-1704, Sep 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#phan2020improvingenhancement">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/lsp.2020.3025020">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="phan2020personalizedregularization">51</a>]
</dt>
<dd>
H&nbsp;Phan, K&nbsp;Mikkelsen, OY&nbsp;Chén, P&nbsp;Koch, A&nbsp;Mertins, P&nbsp;Kidmose, and M&nbsp;De&nbsp;Vos.
 Personalized automatic sleep staging with single-night data: a pilot
  study with kl-divergence regularization.
 <em>Physiological Measurement</em>, Jun 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#phan2020personalizedregularization">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1088/1361-6579/ab921e">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="politimou2020melodicchildren">52</a>]
</dt>
<dd>
N&nbsp;Politimou, P&nbsp;Douglass-Kirk, M&nbsp;Pearce, L&nbsp;Stewart, and F&nbsp;Franco.
 Melodic expectations in 5- and 6-year-old children.
 <em>Journal of Experimental Child Psychology</em>, 203, Nov 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#politimou2020melodicchildren">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.jecp.2020.105020">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="proutskova2020fromethnomusicontology">53</a>]
</dt>
<dd>
P&nbsp;Proutskova, A&nbsp;Volk, P&nbsp;Heidarian, and G&nbsp;Fazekas.
 From music ontology towards ethno-music-ontology.
 In <em>
  https://www.ismir2020.net/assets/img/proceedings/2020_ISMIR_Proceedings.pdf</em>,
  pages 923-931. Montreal, Canada, Oct 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#proutskova2020fromethnomusicontology">bib</a>&nbsp;| 
<a href="http://semantiaudio.net/">http</a>&nbsp;]

</dd>


<dt>
[<a name="quirogamartinez2020decomposingsystem">54</a>]
</dt>
<dd>
DR&nbsp;Quiroga-Martinez, NC&nbsp;Hansen, A&nbsp;Højlund, M&nbsp;Pearce, E&nbsp;Brattico, and P&nbsp;Vuust.
 Decomposing neural responses to melodic surprise in musicians and
  non-musicians: Evidence for a hierarchy of predictions in the auditory
  system.
 <em>NeuroImage</em>, 215, Apr 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#quirogamartinez2020decomposingsystem">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.neuroimage.2020.116816">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="quirogamartinez2020musicalnonmusicians">55</a>]
</dt>
<dd>
DR&nbsp;Quiroga-Martinez, NC&nbsp;Hansen, A&nbsp;Højlund, M&nbsp;Pearce, E&nbsp;Brattico, and P&nbsp;Vuust.
 Musical prediction error responses similarly reduced by predictive
  uncertainty in musicians and non-musicians.
 <em>European Journal of Neuroscience</em>, Jan 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#quirogamartinez2020musicalnonmusicians">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1101/754333">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="ragano2020audiorepresentation">56</a>]
</dt>
<dd>
A&nbsp;Ragano, E&nbsp;Benetos, and A&nbsp;Hines.
 Audio impairment recognition using a correlation-based feature
  representation.
 In <em>http://qomex2020.ie/</em>. Athlone, Ireland, IEEE, May 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#ragano2020audiorepresentation">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/QoMEX48832.2020.9123111">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="ragano2020developmentconditions">57</a>]
</dt>
<dd>
A&nbsp;Ragano, E&nbsp;Benetos, and A&nbsp;Hines.
 Development of a speech quality database under uncontrolled
  conditions.
 Shanghai, China, Oct 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#ragano2020developmentconditions">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Interspeech.2020-1899">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="rohanian2020multimodalspeech">58</a>]
</dt>
<dd>
M&nbsp;Rohanian, J&nbsp;Hough, and M&nbsp;Purver.
 Multi-modal fusion with gating using audio, lexical and disfluency
  features for alzheimer's dementia recognition from spontaneous speech.
 In <em>Proceedings of the Annual Conference of the International
  Speech Communication Association, INTERSPEECH</em>, volume 2020-October, pages
  2187-2191, Oct 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#rohanian2020multimodalspeech">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Interspeech.2020-2721">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="saitis2020brightnesscategories">59</a>]
</dt>
<dd>
C&nbsp;Saitis and K&nbsp;Siedenburg.
 Brightness perception for musical instrument sounds: Relation to
  timbre dissimilarity and source-cause categories.
 <em>The Journal of the Acoustical Society of America</em>,
  148(4):2256-2266, Oct 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#saitis2020brightnesscategories">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1121/10.0002275">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="Sarmento2020">60</a>]
</dt>
<dd>
Pedro Sarmento, Ove Holmqvist, and Mathieu Barthet.
 Musical Smart City: Perspectives on Ubiquitous Sonification.
 In <em>Proceedings of the 2020 Ubiquitous Music Workshop</em>, 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#Sarmento2020">bib</a>&nbsp;]

</dd>


<dt>
[<a name="shatri2020opticalchallenges">61</a>]
</dt>
<dd>
E&nbsp;Shatri and G&nbsp;Fazekas.
 Optical music recognition: State of the art and major challenges.
 Hamburg, May 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#shatri2020opticalchallenges">bib</a>&nbsp;| 
<a href="https://www.elonashatri.co.uk/">http</a>&nbsp;]

</dd>


<dt>
[<a name="shekhar2020automatingestonian">62</a>]
</dt>
<dd>
R&nbsp;Shekhar, M&nbsp;Pranjić, S&nbsp;Pollak, A&nbsp;Pelicon, and M&nbsp;Purver.
 Automating news comment moderation with limited resources:
  Benchmarking in croatian and estonian.
 <em>Journal of Language Technology and Computational Linguistics</em>,
  34(1):49-79, Sep 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#shekhar2020automatingestonian">bib</a>&nbsp;| 
<a href="https://jlcl.org/content/2-allissues/1-heft1-2020/jlcl_2020-1_3.pdf">.pdf</a>&nbsp;]

</dd>


<dt>
[<a name="soave2020areality">63</a>]
</dt>
<dd>
F&nbsp;Soave, N&nbsp;Bryan-Kinns, and I&nbsp;Farkhatdinov.
 A preliminary study on full-body haptic stimulation on modulating
  self-motion perception in virtual reality.
 Aug 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#soave2020areality">bib</a>&nbsp;]

</dd>


<dt>
[<a name="solomes2020efficientsystem">64</a>]
</dt>
<dd>
AM&nbsp;Solomes and D&nbsp;Stowell.
 Efficient bird sound detection on the bela embedded system.
 In <em>ICASSP, IEEE International Conference on Acoustics, Speech
  and Signal Processing - Proceedings</em>, volume 2020-May, pages 746-750, May
  2020.
[&nbsp;<a href="pubs2020_raw_bib.html#solomes2020efficientsystem">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP40776.2020.9053533">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="steinmetz2020randomizednetworks">65</a>]
</dt>
<dd>
CJ&nbsp;Steinmetz and JD&nbsp;Reiss.
 Randomized overdrive neural networks.
 Dec 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#steinmetz2020randomizednetworks">bib</a>&nbsp;]

</dd>


<dt>
[<a name="stockman2020exploringpriming">66</a>]
</dt>
<dd>
A&nbsp;Stockman and F&nbsp;Feng.
 Exploring crossmodal perceptual enhancement and integration in a
  sequence reproducing task with cognitive priming.
 <em>Journal on Multimodal User Interfaces</em>, Jul 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#stockman2020exploringpriming">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/s12193-020-00326-y">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="stockman2020theobjects">67</a>]
</dt>
<dd>
A&nbsp;Stockman and S&nbsp;WILKIE.
 The effect of audio cues and sound source stimuli on the perception
  of approaching objects.
 <em>Applied Acoustics</em>, May 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#stockman2020theobjects">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.apacoust.2020.107388">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="stoller2020sequnetmodelling">68</a>]
</dt>
<dd>
D&nbsp;Stoller, M&nbsp;Tian, S&nbsp;Ewert, and S&nbsp;Dixon.
 Seq-u-net: A one-dimensional causal u-net for efficient sequence
  modelling.
 In <em>IJCAI International Joint Conference on Artificial
  Intelligence</em>, volume 2021-January, pages 2893-2900, Jan 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#stoller2020sequnetmodelling">bib</a>&nbsp;]

</dd>


<dt>
[<a name="stowell2020auk">69</a>]
</dt>
<dd>
D&nbsp;Stowell, J&nbsp;Kelly, D&nbsp;Tanner, J&nbsp;Taylor, E&nbsp;Jones, J&nbsp;Geddes, and E&nbsp;Chalstrey.
 A harmonised, high-coverage, open dataset of solar photovoltaic
  installations in the uk.
 <em>Scientific Data</em>, 7(1), Dec 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#stowell2020auk">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1038/s41597-020-00739-0">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="stowell2020ecoacousticsscale">70</a>]
</dt>
<dd>
D&nbsp;Stowell and J&nbsp;Sueur.
 Ecoacoustics: acoustic sensing for biodiversity monitoring at scale.
 <em>Remote Sensing in Ecology and Conservation</em>, 6(3):217-219, Aug
  2020.
[&nbsp;<a href="pubs2020_raw_bib.html#stowell2020ecoacousticsscale">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1002/rse2.174">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="subramanian2020aclassification">71</a>]
</dt>
<dd>
V&nbsp;SUBRAMANIAN, A&nbsp;Pankajakshan, E&nbsp;Benetos, N&nbsp;Xu, S&nbsp;McDonald, and M&nbsp;Sandler.
 A study on the transferability of adversarial attacks in sound event
  classification.
 pages 301-305. Barcelona, Spain, IEEE, May 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#subramanian2020aclassification">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP40776.2020.9054445">DOI</a>&nbsp;| 
<a href="https://2020.ieeeicassp.org/">http</a>&nbsp;]

</dd>


<dt>
[<a name="tabaktemporalmedia">72</a>]
</dt>
<dd>
T&nbsp;Tabak and M&nbsp;Purver.
 Temporal mental health dynamics on social media.
[&nbsp;<a href="pubs2020_raw_bib.html#tabaktemporalmedia">bib</a>&nbsp;| 
<a href="http://arxiv.org/abs/2008.13121v3">http</a>&nbsp;]

</dd>


<dt>
[<a name="tabak2020temporalmedia">73</a>]
</dt>
<dd>
T&nbsp;Tabak and M&nbsp;Purver.
 Temporal mental health dynamics on social media.
 In K&nbsp;Verspoor, KB&nbsp;Cohen, M&nbsp;Conway, BD&nbsp;Bruijn, M&nbsp;Dredze, R&nbsp;Mihalcea,
  and BC&nbsp;Wallace, editors, <em>NLP4COVID@EMNLP</em>. Association for Computational
  Linguistics, 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#tabak2020temporalmedia">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.18653/v1/2020.nlpcovid19-2.7">DOI</a>&nbsp;| 
<a href="https://www.aclweb.org/anthology/volumes/2020.nlpcovid19-2/">http</a>&nbsp;]

</dd>


<dt>
[<a name="thompson2020posterdevelopers">74</a>]
</dt>
<dd>
A&nbsp;Thompson, G&nbsp;Fazekas, and G&nbsp;Wiggins.
 Poster: Programming practices among interactive audio software
  developers.
 In <em>Proceedings of IEEE Symposium on Visual Languages and
  Human-Centric Computing, VL/HCC</em>, volume 2020-August, Aug 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#thompson2020posterdevelopers">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/VL/HCC50065.2020.9127261">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="turchet2020theontology">75</a>]
</dt>
<dd>
L&nbsp;Turchet, F&nbsp;Antoniazzi, F&nbsp;Viola, F&nbsp;Giunchiglia, and G&nbsp;Fazekas.
 The internet of musical things ontology.
 <em>Journal of Web Semantics</em>, 60, Jan 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#turchet2020theontology">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.websem.2020.100548">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="turchet2020thechallenges">76</a>]
</dt>
<dd>
L&nbsp;Turchet, G&nbsp;Fazekas, M&nbsp;Lagrange, HS&nbsp;Ghadikolaei, and C&nbsp;Fischione.
 The internet of audio things: State of the art, vision, and
  challenges.
 <em>IEEE Internet of Things Journal</em>, 7(10):10233-10249, May 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#turchet2020thechallenges">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/jiot.2020.2997047">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="turchet2020cloudsmartinteractions">77</a>]
</dt>
<dd>
L&nbsp;Turchet, J&nbsp;Pauwels, C&nbsp;Fischione, and G&nbsp;Fazekas.
 Cloud-smart musical instrument interactions.
 <em>ACM Transactions on Internet of Things</em>, 1(3):1-29, Jul 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#turchet2020cloudsmartinteractions">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3377881">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="vidaavila2020lowcostmonitoring">78</a>]
</dt>
<dd>
E&nbsp;Vidaña-Vila, J&nbsp;Navarro, C&nbsp;Borda-Fortuny, D&nbsp;Stowell, and RM&nbsp;Alsina-Pagès.
 Low-cost distributed acoustic sensor network for real-time urban
  sound monitoring.
 <em>Electronics (Switzerland)</em>, 9(12):1-25, Dec 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#vidaavila2020lowcostmonitoring">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.3390/electronics9122119">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="wang2020playingscattering">79</a>]
</dt>
<dd>
C&nbsp;Wang, V&nbsp;Lostanlen, E&nbsp;Benetos, and E&nbsp;Chew.
 Playing technique recognition by joint time–frequency scattering.
 pages 881-885. Barcelona, Spain, May 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#wang2020playingscattering">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP40776.2020.9053474">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="wang2020oncultures">80</a>]
</dt>
<dd>
W&nbsp;Wang, N&nbsp;Bryan-Kinns, and JG&nbsp;Sheridan.
 On the role of in-situ making and evaluation in designing across
  cultures.
 <em>CoDesign</em>, 16(3):233-250, Jul 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#wang2020oncultures">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1080/15710882.2019.1580296">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="wei2020acrnndetection">81</a>]
</dt>
<dd>
W&nbsp;Wei, H&nbsp;Zhu, E&nbsp;Benetos, and Y&nbsp;Wang.
 A-crnn: a domain adaptation model for sound event detection.
 pages 276-280. Barcelona, Spain, IEEE, May 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#wei2020acrnndetection">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP40776.2020.9054248">DOI</a>&nbsp;| 
<a href="https://2020.ieeeicassp.org/">http</a>&nbsp;]

</dd>


<dt>
[<a name="williams2020onmusic">82</a>]
</dt>
<dd>
D&nbsp;Williams, B&nbsp;Fazenda, V&nbsp;Williamson, and G&nbsp;Fazekas.
 On performance and perceived effort in trail runners using sensor
  control to generate biosynchronous music.
 <em>Sensors (Basel, Switzerland)</em>, 20(16):1-14, Aug 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#williams2020onmusic">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.3390/s20164528">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="wilmering2020aeffects">83</a>]
</dt>
<dd>
T&nbsp;WILMERING, DJ&nbsp;MOFFAT, A&nbsp;Milo, and M&nbsp;Sandler.
 A history of audio effects.
 <em>Applied Sciences</em>, 10(3), Jan 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#wilmering2020aeffects">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.3390/app10030791">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="wrightcreativereflection">84</a>]
</dt>
<dd>
G&nbsp;Wright and M&nbsp;Purver.
 Creative language generation in a society of engagement and
  reflection.
 Coimbra.
[&nbsp;<a href="pubs2020_raw_bib.html#wrightcreativereflection">bib</a>&nbsp;]

</dd>


<dt>
[<a name="ycart2020learninglstms">85</a>]
</dt>
<dd>
A&nbsp;Ycart and E&nbsp;Benetos.
 Learning and evaluation methodologies for polyphonic music sequence
  prediction with lstms.
 <em>IEEE/ACM Transactions on Audio, Speech and Language Processing</em>,
  28(1):1328-1341, Dec 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#ycart2020learninglstms">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TASLP.2020.2987130">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="ycart2020investigatingtranscription">86</a>]
</dt>
<dd>
A&nbsp;Ycart, L&nbsp;Liu, E&nbsp;Benetos, and M&nbsp;Pearce.
 Investigating the perceptual validity of evaluation metrics for
  automatic piano music transcription.
 <em>Transactions of the International Society for Music Information
  Retrieval</em>, 3(1):68-81, Jun 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#ycart2020investigatingtranscription">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.5334/tismir.57">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="ycart2020musicalevaluation">87</a>]
</dt>
<dd>
A&nbsp;Ycart, L&nbsp;Liu, E&nbsp;Benetos, and MT&nbsp;Pearce.
 Musical features for automatic music transcription evaluation.
 Technical report, Apr 2020.
 Technical report.
[&nbsp;<a href="pubs2020_raw_bib.html#ycart2020musicalevaluation">bib</a>&nbsp;| 
<a href="http://arxiv.org/abs/2004.07171v1">http</a>&nbsp;]

</dd>


<dt>
[<a name="zacharakis2020evidencepresentation">88</a>]
</dt>
<dd>
A&nbsp;ZACHARAKIS, B&nbsp;Hayes, C&nbsp;Saitis, and K&nbsp;Pastiadis.
 Evidence for timbre space robustness to an uncontrolled online
  stimulus presentation.
 In <em>Proceedings of the 2nd International Conference on Timbre</em>,
  pages 129-132. Thessaloniki (Online), Sep 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#zacharakis2020evidencepresentation">bib</a>&nbsp;]

</dd>


<dt>
[<a name="zhang2020exploitingactivities">89</a>]
</dt>
<dd>
H&nbsp;Zhang, K&nbsp;Zhang, and N&nbsp;Bryan-Kinns.
 Exploiting the emotional preference of music for music recommendation
  in daily activities.
 In <em>Proceedings - 2020 13th International Symposium on
  Computational Intelligence and Design, ISCID 2020</em>, pages 350-353, Dec 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#zhang2020exploitingactivities">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ISCID51228.2020.00085">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="zhao2020identifyingfeatures">90</a>]
</dt>
<dd>
Y&nbsp;Zhao, G&nbsp;Fazekas, and M&nbsp;Sandler.
 Identifying master violinists using note-level audio features.
 In <em>Proceedings of the Sound and Music Computing Conferences</em>,
  volume 2020-June, pages 185-192, Jan 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#zhao2020identifyingfeatures">bib</a>&nbsp;]

</dd>


<dt>
[<a name="zioga2020auditorystyle">91</a>]
</dt>
<dd>
I&nbsp;Zioga, PMC Harrison, MT&nbsp;Pearce, J&nbsp;Bhattacharya, and CDB Luft.
 Auditory but not audiovisual cues lead to higher neural sensitivity
  to the statistical regularities of an unfamiliar musical style.
 <em>Journal of Cognitive Neuroscience</em>, 32(12):2241-2259, Oct 2020.
[&nbsp;<a href="pubs2020_raw_bib.html#zioga2020auditorystyle">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1162/jocn_a_01614">DOI</a>&nbsp;]

</dd>
</dl><hr><p><em>This file was generated by
<a href="http://www.lri.fr/~filliatr/bibtex2html/">bibtex2html</a> 1.96.</em></p>
