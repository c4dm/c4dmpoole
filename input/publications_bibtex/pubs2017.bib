% This file was created with JabRef 2.10.
% Encoding: ISO8859_1


@InProceedings{morfi2017deductiverecordings,
  Title                    = {Deductive Refinement of Species Labelling in Weakly Labelled Birdsong Recordings},
  Author                   = {Morfi, V and STOWELL, DF},
  Booktitle                = {International Conference on Acoustics, Speech and Signal Processing (ICASSP2017 )},
  Year                     = {2017},
  Organization             = {New Orleans, USA},

  Abstract                 = {Many approaches have been used in bird species classification from their sound in order to provide labels for the whole of a recording. However, a more precise classification of each bird vocalization would be of great importance to the use and management of sound archives and bird monitoring. In this work, we introduce a technique that using a two step process can first automatically detect all bird vocalizations and then, with the use of ‘weakly’ labelled recordings, classify them. Evaluations of our proposed method show that it achieves a correct classification of 75.4\% when used in a synthetic dataset.},
  Finishday                = {9},
  Finishmonth              = {Mar},
  Finishyear               = {2017},
  Publicationstatus        = {published},
  Startday                 = {5},
  Startmonth               = {Mar},
  Startyear                = {2017}
}

@Article{zacharakis2017rearrangementcorrelates,
  Title                    = {Rearrangement of Timbre Space Due To Background Noise: Behavioural Evidence and Acoustic Correlates},
  Author                   = {Zacharakis, A and Terrell, M and Simpson, AR and Pastiadis, K and Reiss, J},
  Journal                  = {Acta Acustica united with Acustica},
  Year                     = {2017},

  Month                    = {Mar},
  Pages                    = {288--298},
  Volume                   = {103},

  Day                      = {1},
  Doi                      = {10.3813/AAA.919057},
  ISSN                     = {1610-1928},
  Issue                    = {2},
  Publicationstatus        = {published}
}

@Article{reiss2017userparameters,
  Title                    = {User Preference on Artificial Reverberation and Delay Time Parameters},
  Author                   = {REISS, J},
  Journal                  = {Journal of the Audio Engineering Society},
  Year                     = {2017},

  Month                    = {Feb},

  Day                      = {16},
  ISSN                     = {1549-4950},
  Publicationstatus        = {published},
  Publisher                = {Audio Engineering Society}
}

@Article{reiss2017perceptualproduction,
  Title                    = {Perceptual evaluation and analysis of reverberation in multitrack music production},
  Author                   = {REISS, J and De Man, B},
  Journal                  = {Journal of the Audio Engineering Society},
  Year                     = {2017},

  Month                    = {Feb},

  Day                      = {16},
  Doi                      = {10.17743/jaes.2016.0062},
  ISSN                     = {1549-4950},
  Publicationstatus        = {published},
  Publisher                = {Audio Engineering Society}
}

@Article{chourdakis2017areverberation,
  Title                    = {A Machine-Learning Approach to Application of Intelligent Artificial Reverberation},
  Author                   = {Chourdakis, E and REISS, J},
  Journal                  = {Journal of the Audio Engineering Society},
  Year                     = {2017},

  Month                    = {Feb},
  Volume                   = {65},

  Abstract                 = {We propose a design of an adaptive digital audio effect for artificial reverberation, controlled
directly by desired reverberation characteristics, that allows it to learn from the user in a super-
vised way. The user provides monophonic examples of desired reverberation characteristics
for individual tracks taken from the Open Multitrack Testbed. We use this data to train a set of
models to automatically apply reverberation to similar tracks. We evaluate those models using
classifier f1-scores, mean squared errors, and multi-stimulus listening tests.},
  Day                      = {16},
  ISSN                     = {1549-4950},
  Publicationstatus        = {published},
  Publisher                = {Audio Engineering Society}
}

@Article{halpern2017thatexpectation.,
  Title                    = {That note sounds wrong! Age-related effects in processing of musical expectation.},
  Author                   = {Halpern, AR and Zioga, I and Shankleman, M and Lindsen, J and Pearce, MT and Bhattacharya, J},
  Journal                  = {Brain Cogn},
  Year                     = {2017},

  Month                    = {Apr},
  Pages                    = {1--9},
  Volume                   = {113},

  Abstract                 = {Part of musical understanding and enjoyment stems from the ability to accurately predict what note (or one of a small set of notes) is likely to follow after hearing the first part of a melody. Selective violation of expectations can add to aesthetic response but radical or frequent violations are likely to be disliked or not comprehended. In this study we investigated whether a lifetime of exposure to music among untrained older adults would enhance their reaction to unexpected endings of unfamiliar melodies. Older and younger adults listened to melodies that had expected or unexpected ending notes, according to Western music theory. Ratings of goodness-of-fit were similar in the groups, as was ERP response to the note onset (N1). However, in later time windows (P200 and Late Positive Component), the amplitude of a response to unexpected and expected endings was both larger in older adults, corresponding to greater sensitivity, and more widespread in locus, consistent with a dedifferentiation pattern. Lateralization patterns also differed. We conclude that older adults refine their understanding of this important aspect of music throughout life, with the ability supported by changing patterns of neural activity.},
  Doi                      = {10.1016/j.bandc.2016.12.006},
  Eissn                    = {1090-2147},
  Keyword                  = {Aging},
  Language                 = {eng},
  Organization             = {United States},
  Pii                      = {S0278-2626(16)30043-4},
  Publicationstatus        = {published},
  Url                      = {https://www.ncbi.nlm.nih.gov/pubmed/28064077}
}

@Article{agres2017information-theoreticmemory,
  Title                    = {Information-Theoretic Properties of Auditory Sequences Dynamically Influence Expectation and Memory},
  Author                   = {Agres, K and Abdallah, S and Pearce, M},
  Journal                  = {Cognitive Science},
  Year                     = {2017},

  Month                    = {Jan},

  Day                      = {25},
  Doi                      = {10.1111/cogs.12477},
  ISSN                     = {0364-0213},
  Publicationstatus        = {published}
}

@InProceedings{morreale2017buildingplatform,
  Title                    = {Building a Maker Community Around an Open Hardware Platform},
  Author                   = {Morreale, F and Moro, G and Chamberlain, A and Benford, S and MCPHERSON, A},
  Booktitle                = {ACM SIGCHI Conference on Human Factors in Computing Systems (CHI)},
  Year                     = {2017},
  Month                    = {May},
  Organization             = {Denver, CO, USA},

  Abstract                 = {This paper reflects on the dynamics and practices of building a maker community around a new hardware platform. We examine the factors promoting the successful uptake of a maker platform from two perspectives: first, we investigate the technical and user experience considerations that users identify as the most important. Second, we explore the specific activities that help attract a community and encourage sustained participation. We present an inductive approach based on the case study of Bela, an embedded platform for creating interactive audio systems. The technical design and community building processes are detailed, culminating in a successful crowdfunding campaign. To further understand the community dynamics, the paper also presents an intensive three-day workshop with eight digital musical instrument designers. From observations and interviews, we reflect on the relationship between the platform and the community and offer suggestions for HCI researchers and practitioners interested in establishing their own maker communities.},
  Day                      = {6},
  Finishday                = {11},
  Finishmonth              = {May},
  Finishyear               = {2017},
  Publicationstatus        = {accepted},
  Startday                 = {6},
  Startmonth               = {May},
  Startyear                = {2017}
}

@InProceedings{herremans2017atension,
  Title                    = {A multi-modal platform for semantic music analysis: visualizing audio- and score-based tension},
  Author                   = {HERREMANS, D and Chuan, CH},
  Booktitle                = {IEEEInternational Conference on Semantic Computing},
  Year                     = {2017},
  Month                    = {Jan},
  Organization             = {San Diego},

  Day                      = {29},
  Finishday                = {1},
  Finishmonth              = {Feb},
  Finishyear               = {2017},
  Publicationstatus        = {published},
  Startday                 = {30},
  Startmonth               = {Jan},
  Startyear                = {2017}
}

@Article{agres2017harmonicmusic,
  Title                    = {Harmonic Structure Predicts the Enjoyment of Uplifting Trance Music},
  Author                   = {Agres, K and Herremans, D and Bigo, L and Conklin, D},
  Journal                  = {Frontiers in Psychology},
  Year                     = {2017},

  Month                    = {Jan},
  Volume                   = {7},

  Abstract                 = {© 2017 Agres, Herremans, Bigo and Conklin.An empirical investigation of how local harmonic structures (e.g., chord progressions) contribute to the experience and enjoyment of uplifting trance (UT) music is presented. The connection between rhythmic and percussive elements and resulting trance-like states has been highlighted by musicologists, but no research, to our knowledge, has explored whether repeated harmonic elements influence affective responses in listeners of trance music. Two alternative hypotheses are discussed, the first highlighting the direct relationship between repetition/complexity and enjoyment, and the second based on the theoretical inverted-U relationship described by the Wundt curve. We investigate the connection between harmonic structure and subjective enjoyment through interdisciplinary behavioral and computational methods: First we discuss an experiment in which listeners provided enjoyment ratings for computer-generated UT anthems with varying levels of harmonic repetition and complexity. The anthems were generated using a statistical model trained on a corpus of 100 uplifting trance anthems created for this purpose, and harmonic structure was constrained by imposing particular repetition structures (semiotic patterns defining the order of chords in the sequence) on a professional UT music production template. Second, the relationship between harmonic structure and enjoyment is further explored using two computational approaches, one based on average Information Content, and another that measures average tonal tension between chords. The results of the listening experiment indicate that harmonic repetition does in fact contribute to the enjoyment of uplifting trance music. More compelling evidence was found for the second hypothesis discussed above, however some maximally repetitive structures were also preferred. Both computational models provide evidence for a Wundt-type relationship between complexity and enjoyment. By systematically manipulating the structure of chord progressions, we have discovered specific harmonic contexts in which repetitive or complex structure contribute to the enjoyment of uplifting trance music.},
  Day                      = {10},
  Doi                      = {10.3389/fpsyg.2016.01999},
  Eissn                    = {1664-1078},
  Issue                    = {JAN},
  Publicationstatus        = {published}
}

@Article{mehrabi2017vocalcentroid,
  Title                    = {Vocal imitation of synthesised sounds varying in pitch, loudness and spectral centroid},
  Author                   = {MEHRABI, A and Dixon, S and Sandler},
  Journal                  = {Journal of the Acoustical Society of America},
  Year                     = {2017},

  Month                    = {Feb},
  Pages                    = {783--796},
  Volume                   = {141},

  Abstract                 = {Vocal imitations are often used to convey sonic ideas [Lemaitre, Dessein, Susini, and Aura.
(2011). Ecol. Psych.
23
(4), 267–307]. For computer based systems to interpret these vocalisations,
it is advantageous to apply knowledge of what happens when people vocalise sounds where the
acoustic features have different temporal envelopes. In the present study, 19 experienced musi-
cians and music producers were asked to imitate 44 sounds with one or two feature envelopes
applied. The study addresses two main questions: (1) How accurately can people imitate ramp and
modulation envelopes for pitch, loudness, and spectral centroid?; (2) What happens to this accu-
racy when people are asked to imitate two feature envelopes simultaneously? The results show
that experienced musicians can imitate pitch, loudness, and spectral centroid accurately, and that
imitation accuracy is generally preserved when the imitated stimuli combine two, non-necessarily
congruent features. This demonstrates the viability of using the voice as a natural means of
expressing time series of two features simultaneously.},
  Day                      = {13},
  Doi                      = {10.1121/1.4974825},
  ISSN                     = {1520-8524},
  Issue                    = {2},
  Publicationstatus        = {published},
  Publisher                = {Acoustical Society of America},
  Url                      = {http://asa.scitation.org/doi/abs/10.1121/1.4974825}
}

@Article{wu2017openperformances,
  Title                    = {Open Symphony: Creative Participation for Audiences of Live Music Performances},
  Author                   = {Wu, Y and Zhang, L and Bryan-Kinns, N and Barthet, M},
  Journal                  = {IEEE Multimedia},
  Year                     = {2017},

  Month                    = {Jan},
  Pages                    = {48--62},
  Volume                   = {24},

  Abstract                 = {© 1994-2012 IEEE.Most contemporary Western performing arts practices restrict creative interactions from audiences. Open Symphony is designed to explore audience-performer interaction in live music performances, assisted by digital technology. Audiences can conduct improvising performers by voting for various musical 'modes.' Technological components include a web-based mobile application, a visual client displaying generated symbolic scores, and a server service for the exchange of creative data. The interaction model, app, and visualization were designed through an iterative participatory design process. The system was experienced by about 120 audience and performer participants (35 completed surveys) in controlled (lab) and real-world settings. Feedback on usability and user experience was overall positive, and live interactions demonstrate significant levels of audience creative engagement. The authors identified further design challenges around audience sense of control, learnability, and compositional structure. This article is part of a special issue on multimedia for enriched music.},
  Day                      = {1},
  Doi                      = {10.1109/MMUL.2017.19},
  ISSN                     = {1070-986X},
  Issue                    = {1},
  Publicationstatus        = {published}
}

@InProceedings{benetos2017polyphonicsystems,
  Title                    = {Polyphonic note and instrument tracking using linear dynamical systems},
  Author                   = {Benetos, E},
  Booktitle                = {2017 AES International Conference on Semantic Audio},
  Year                     = {2017},
  Month                    = {Jun},
  Organization             = {Erlangen, Germany},
  Publisher                = {Audio Engineering Society},

  Abstract                 = {In this paper, a system for automatic transcription of multiple-instrument polyphonic music is proposed, which supports tracking multiple concurrent notes using linear dynamical systems (LDS). The system is based on a spectrogram factorisation model which extends probabilistic latent component analysis (PLCA), and supports the detection of multiple pitches, instrument contributions, and pitch deviations. In order to jointly track multiple concurrent pitches, the use of LDS as prior to the PLCA model is proposed. LDS parameters are learned in a training stage using score-informed transcriptions; for LDS inference, online and offline variants are evaluated. The MAPS piano music dataset and the Bach10 multi-instrument dataset are used for note tracking experiments, with the latter dataset also being evaluated with respect to instrument assignment performance. Results show that the proposed LDS-based method can successfully track multiple concurrent notes, leading to an improvement of over 3\% in terms of note-based F-measure for both datasets over benchmark note tracking approaches.},
  Day                      = {22},
  Finishday                = {24},
  Finishmonth              = {Jun},
  Finishyear               = {2017},
  Publicationstatus        = {accepted},
  Startday                 = {22},
  Startmonth               = {Jun},
  Startyear                = {2017},
  Url                      = {http://www.aes.org/conferences/2017/semantic/}
}

@InProceedings{valero-mas2017assessingtranscription,
  Title                    = {Assessing the Relevance of Onset Information for Note Tracking in Piano Music Transcription},
  Author                   = {Valero-Mas, JJ and Benetos, E and Iñesta, JM},
  Booktitle                = {2017 AES International Conference on Semantic Audio},
  Year                     = {2017},
  Month                    = {Jun},
  Organization             = {Erlangen, Germany},
  Publisher                = {Audio Engineering Society},

  Day                      = {22},
  Finishday                = {24},
  Finishmonth              = {Jun},
  Finishyear               = {2017},
  Publicationstatus        = {accepted},
  Startday                 = {22},
  Startmonth               = {Jun},
  Startyear                = {2017},
  Url                      = {http://www.aes.org/conferences/2017/semantic/}
}

@InProceedings{russell2017onmodels,
  Title                    = {On the Memory Properties of Recurrent Neural Models},
  Author                   = {Russell, AJ and Benetos, E and d'Avila Garcez, AS},
  Booktitle                = {International Joint Conference on Neural Networks (IJCNN 2017)},
  Year                     = {2017},
  Month                    = {May},
  Organization             = {Anchorage, Alaska, USA},

  Abstract                 = {In this paper, we investigate the memory properties of two popular gated units: long short term memory (LSTM) and gated recurrent units (GRU), which have been used in recurrent neural networks (RNN) to achieve state-of-the-art performance on several machine learning tasks. We propose five basic tasks for isolating and examining specific capabilities relating to the implementation of memory. Results show that (i) both types of gated unit perform less reliably than standard RNN units on tasks testing fixed delay recall, (ii) the reliability of stochastic gradient descent decreases as network complexity increases, and (iii) gated units are found to perform better than standard RNNs on tasks that require values to be stored in memory and updated conditionally upon input to the network. Task performance is found to be surprisingly independent of network depth (number of layers) and connection architecture. Finally, visualisations of the solutions found by these networks are presented and explored, exposing for the first time how logic operations are implemented by individual gated cells and small groups of these cells.},
  Day                      = {14},
  Finishday                = {14},
  Finishmonth              = {May},
  Finishyear               = {2017},
  Publicationstatus        = {accepted},
  Startday                 = {19},
  Startmonth               = {May},
  Startyear                = {2017}
}

@Article{abdallah2017themusicology,
  Title                    = {The Digital Music Lab: A Big Data Infrastructure for Digital Musicology},
  Author                   = {Abdallah, S and Benetos, E and Gold, N and Hargreaves, S and Weyde, T and Wolff, D},
  Journal                  = {ACM Journal on Computing and Cultural Heritage},
  Year                     = {2017},

  Month                    = {Jan},
  Volume                   = {10},

  Day                      = {1},
  Doi                      = {10.1145/2983918},
  ISSN                     = {1556-4673},
  Issue                    = {1},
  Publicationstatus        = {published},
  Publisher                = {ACM},
  Url                      = {http://jocch.acm.org/}
}

@InProceedings{liang2017detection,
  Title                    = {Detection of Piano Pedaling Techniques on the Sustain Pedal},
  Author                   = {Liang, B and Fazekas, G and Sandler, M},
  Booktitle                = {http://www.aes.org/e-lib/},
  Year                     = {2017},
  Month                    = {Octobor},
  Organization             = {New York, USA},
  Publisher                = {Audio Engineering Society},

  Abstract                 = {Automatic detection of piano pedalling techniques is challenging as it is comprised of subtle nuances of piano timbres. In this paper, we address this problem on single notes using decision-tree-based support vector machines. Features are extracted from harmonics and residuals based on physical acoustics considerations and signal observations. We consider four distinct pedalling techniques on the sustain pedal (anticipatory full, anticipatory half, legato full and legato half pedalling) and create a new isolated-note dataset consisting of different pitches and velocities for each pedalling technique plus notes played without pedal. Our results using cross-validation trails show the effectiveness of the designed features and the trained classifiers for discriminating pedalling techniques.},
  Conference               = {143rd Convention of the Audio Engineering Society},
  Day                      = {18},
  Finishday                = {21},
  Finishmonth              = {Octobor},
  Finishyear               = {2017},
  Keyword                  = {piano pedal},
  Publicationstatus        = {online-published},
  Startday                 = {18},
  Startmonth               = {Octobor},
  Startyear                = {2017},
  Timestamp                = {2018.02.06},
  Url                      = {http://www.aes.org/e-lib/browse.cfm?elib=19209}
}


@InProceedings{liang2017recognition,
  Title                    = {Recognition of Piano Pedalling Techniques Using Gesture Data},
  Author                   = {Liang, B and Fazekas, G and Sandler, M},
  Booktitle                = {dl.acm.org},
  Year                     = {2017},
  Month                    = {Aug},
  Organization             = {Queen Mary University of London, London},
  Publisher                = {ACM},
  Volume                   = {Proceedings of AM ’17},

  Abstract                 = {This paper presents a study of piano pedalling technique recognition on the sustain pedal utilising gesture data that is collected using a novel measurement system. The recognition is comprised of two separate tasks: onset/offset detection and classification. The onset and offset time of each pedalling technique was computed through signal processing algorithms. Based on features extracted from every segment when the pedal is pressed, the task of classifying the segments by pedalling technique was undertaken using machine learning methods. We exploited and compared a Support Vector Machine (SVM) and a hidden Markov model (HMM) for classification. Recognition results can be represented by customised pedalling notations and visualised in a score following system.},
  Conference               = {Audio Mostly 2017},
  Day                      = {23},
  Doi                      = {10.1145/3123514.3123535},
  Finishday                = {26},
  Finishmonth              = {Aug},
  Finishyear               = {2017},
  ISBN                     = {978-1-4503-5373-1},
  Keyword                  = {piano pedal},
  Publicationstatus        = {published},
  Startday                 = {23},
  Startmonth               = {Aug},
  Startyear                = {2017},
  Timestamp                = {2018.02.06},
  Url                      = {https://dl.acm.org/citation.cfm?id=3123535}
}

 
@InProceedings{liang2017pianopedaller,
  Title                    = {Piano Pedaller: A Measurement System for Classification and Visualisation of Piano Pedalling Techniques},
  Author                   = {Liang, B and Fazekas, G and McPherson, A and Sandler, M},
  Booktitle                = {http://www.nime.org/archives/},
  Year                     = {2017},
  Month                    = {May},
  Organization             = {Copenhagen, Denmark},
  Publisher                = {New Instruments for Musical Expression},

  Abstract                 = {This paper presents the results of a study of piano pedalling techniques on the sustain pedal using a newly designed measurement system named Piano Pedaller. The system is comprised of an optical sensor mounted in the piano pedal bearing block and an embedded platform for recording audio and sensor data. This enables recording the pedalling gesture of real players and the piano sound under normal playing conditions. Using the gesture data collected from the system, the task of classifying these data by pedalling technique was undertaken using a Support Vector Machine (SVM). Results can be visualised in an audio based score following application to show pedalling together with the player's position in the score.},
  Conference               = {New Instruments for Musical Expression 2017},
  Day                      = {14},
  Finishday                = {19},
  Finishmonth              = {May},
  Finishyear               = {2017},
  Keyword                  = {piano pedal},
  Publicationstatus        = {online-published},
  Startday                 = {14},
  Startmonth               = {May},
  Startyear                = {2017},
  Timestamp                = {2018.02.06},
  Url                      = {http://homes.create.aau.dk/dano/nime17/papers/0062/index.html}
}
