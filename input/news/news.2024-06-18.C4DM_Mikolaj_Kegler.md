### C4DM Seminar: Mikolaj Kegler: Hear What You Want, towards seamless, immersive AI experiences for wearable audio devices
-----------------

#### QMUL, School of Electronic Engineering and Computer Science

#### Centre for Digital Music Seminar Series

**Seminar by:**   
   Mikolaj Kegler

**Date/time:  Tuesday, 18th June 2024, 15pm**

**Location: TBA, Engineering Building, QMUL, E1 4NS **
Zoom: TBA


<b>Title</b>: Hear What You Want, towards seamless, immersive AI experiences for wearable audio devices

-----------------

<b>Abstract</b>: Hear What You Want is both the mission statement and the title of the Bose Research franchise established to build AI-powered experiences for next-generation wearable audio devices. This interdisciplinary franchise involves a wide range of research tracks, such as source separation and sound event detection, to name a few. All these efforts share one common denominator, the resulting solutions must be suitable for low-latency execution on the embedded target devices to enable seamless, immersive experiences. In this talk, I will start by outlining the fundamental problem of limited computational resources on embedded platforms and present our latest methods for building compact yet performant ML models. Subsequently, I will discuss the problem of low-latency causal target source extraction and highlight our recent developments. I will conclude by presenting our latest work on improving the efficiency and fidelity of text-toaudio generative models for Foley sound synthesis. 


<b>Bio</b>: Mikolaj “Miko” Kegler is an Audio Machine Learning Scientist at Bose Corporation. His research at the interface of ML and DSP is focused on developing methods for lightweight, low-latency, on-device speech and audio signal processing. Before joining Bose, Miko was awarded a PhD from the Department of Bioengineering & Centre for Neurotechnology, Imperial College London, where he has been investigating neural mechanisms underlying perception and comprehension of speech, especially in challenging listening conditions. During his PhD, he completed multiple audio ML research placements, including at Amazon Lab126 and Logitech, where he also served as a long-term scientific consultant.

