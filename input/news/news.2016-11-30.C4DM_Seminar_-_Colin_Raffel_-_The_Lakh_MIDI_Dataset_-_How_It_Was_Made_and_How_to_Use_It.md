title: C4DM Seminar: Colin Raffel - The Lakh MIDI Dataset: How It Was Made, and How to Use It
-----------------

<p>For external participants: Please join our <a href="/seminars.html">mailing list</a> to receive announcements of future C4DM seminars.</p>


<span style="font-size: 130%;">Date and Time</span></br>
Wednesday, 30th Nov, at 3:00pm

<span style="font-size: 130%;">Place</span></br>
Room 209, Electronic Engineering building, Queen Mary University of London, Mile End Road, London E1 4NS. Information on how to access the school can be found at <a href="http://www.eecs.qmul.ac.uk/contact-us/">here</a>.

<span style="font-size: 130%;">Speaker</span></br>
Colin Raffel

<span style="font-size: 130%;">Title</span></br>
The Lakh MIDI Dataset: How It Was Made, and How to Use It

<span style="font-size: 130%;">Abstract</span></br>
MIDI files which are matched and aligned to corresponding audio recordings provide a bounty of information for music informatics.  The lack of reliable metadata in MIDI files necessitates content-based analysis for determining whether a MIDI file matches a given audio recording.  We therefore present methods for learning efficient representations of sequential data (e.g., MIDI files and audio spectrograms) using convolutional networks.  Our first approach learns a mapping from sequences of feature vectors to downsampled sequences of binary vectors, providing quadratic speed gains and substantially faster distance calculations.  For further speedup, we present an approximate pruning method which involves embedding sequences as fixed-length vectors in a Euclidean space by using form of attention which integrates over time.  These techniques enabled the creation of the Lakh MIDI dataset, the largest collection of MIDI files which have been matched and aligned to corresponding audio recordings.  I will conclude the talk with a short tutorial demonstrating how to use the dataset and outlining possible uses.

<span style="font-size: 130%;">Bio</span></br>
Colin Raffel is currently a resident at Google Brain, where he researches machine learning techniques for sequential data. He recently completed a PhD in Electrical Engineering at Columbia University In LabROSA, supervised by Dan Ellis.  In 2010, he received a Master's in Music, Science and Technology from Stanford University's CCRMA, supervised by Julius O. Smith III.
