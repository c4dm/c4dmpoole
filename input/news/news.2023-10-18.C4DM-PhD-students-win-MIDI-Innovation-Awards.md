title: C4DM PhD students win at the MIDI Innovation Awards
------------------

<p><img src="news/images/Andrea-Max.png" width="40%" /></p>

<b>Congratulations to two C4DM PhD students, Andrea Martelloni and Max Graf, who have both won MIDI Innovation Awards 2023 in the hardware prototype and software prototype categories, respectively.</b>

Two C4DM PhD students, from the <a href="https://www.aim.qmul.ac.uk/">UKRI Centre for Doctoral Training in Artificial Intelligence and Music (AIM)</a>, have each won an award at this year's MIDI Innovation Awards. Now in its 40th year, the MIDI Awards showcase products and projects that are using MIDI (Musical Instrument Digital Interface) in fresh and original ways, highlighting the role that MIDI technology has to play in enabling musical creativity.

<a href="http://www.eecs.qmul.ac.uk/people/profiles/martelloniandrea.html">Andrea Martelloni</a> won the hardware prototype category for the <a href="https://www.youtube.com/watch?v=oyjAZzyeWxA">HITar</a>, an augmented percussive guitar which Andrea developed under the supervision of Dr Mathieu Barthet and Professor Andrew McPherson. Aimed at percussive fingerstyle guitarists, the HITar is a device that can be fitted to a regular acoustic guitar and can alter the way a player interacts with the instrument’s body. The unit employs sensors placed underneath the areas most commonly struck by players and uses an AI engine to determine which part of the hard is used for each percussive hit. The resulting MIDI output can then be used to integrate hardware or software instruments or samples into a performance, allowing guitarists to trigger drum and percussion samples or blend sample libraries and virtual instruments with their playing.

In the software category, <a href="http://www.eecs.qmul.ac.uk/people/profiles/grafmax.html">Max Graf</a> won for <a href="https://www.youtube.com/watch?v=lFPXLvV7LwU&t=263s">Netz</a>, a mixed reality (MR) software instrument that blends the real and virtual worlds by displaying 3D virtual objects within a real environment. It’s a self-contained instrument that features an embedded sound engine, allowing users to produce sounds directly from the head-mounted display. The software’s interface appears as a network where nodes represent notes, which can be mapped to a tangible surface for tactile feedback or be positioned in the air. Performers’ hand poses and gestures are tracked in in real time, allowing Netz to translate subtle hand movements to expressive musical controls; gestures such as the opening and closing of fingers — or movements such as wrist rotation — are recognised and interpreted by the system and can be assigned to specific instrument parameters and MIDI controls.

Many congratulations from everyone at EECS to Andrea, Max and their supervisors for this huge achievement!

 

More information:
* <a href="https://www.midi.org/innovation-awards">MIDI Innovation Awards</a>
* <a href="https://www.soundonsound.com/news/midi-innovation-awards-2023-winners-announced">Sound on Sound - MIDI Innovation Awards 2023: Winners announced</a>
* HITar <a href="https://twitter.com/the_hitar">Twitter/X</a> and <a href="https://www.instagram.com/the_hitar/">Instagram</a> page



(<i>18 Oct 2023</i>)
